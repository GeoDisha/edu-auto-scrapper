{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ae6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e28895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in ./.venv/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d8207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:61: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:61: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_438802/2056021713.py:61: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  '''\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ================= CONFIG =================\n",
    "\n",
    "OUTPUT_COLLEGE_INFO_FOLDER = \"output_college_info_6_7\"\n",
    "PDF_DOWNLOADS_FOLDER = \"pdf_downloads_final\"\n",
    "DOWNLOAD_TIMEOUT = 90\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"application/pdf,application/octet-stream,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "# ================= HELPERS =================\n",
    "\n",
    "def normalize_pdf_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    NO-OP by design.\n",
    "    URL is returned exactly as provided in Excel.\n",
    "    \"\"\"\n",
    "    return url\n",
    "\n",
    "YEAR_PATTERN = re.compile(\n",
    "    r\"(19\\d{2}|20\\d{2})\\s*(?:[-_/]\\s*(\\d{2}|19\\d{2}|20\\d{2}))?\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "\n",
    "def split_links_with_text(cell_value: str):\n",
    "    \"\"\"\n",
    "    Split a cell into logical (url + text) chunks.\n",
    "    A chunk starts at http(s):// and ends right before the next http(s)://\n",
    "    \"\"\"\n",
    "    if not isinstance(cell_value, str):\n",
    "        return []\n",
    "\n",
    "    text = cell_value.replace(\"\\r\", \" \").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    parts = re.split(r\"(https://|http://)\", text)\n",
    "    chunks = []\n",
    "\n",
    "    i = 1\n",
    "    #print(f\"Original text: {text}...\")\n",
    "    while i < len(parts) - 1:\n",
    "        combined = (parts[i] + parts[i + 1]).strip()\n",
    "        chunks.append(combined)\n",
    "        #print(f\"[DEBUG] Chunk: {combined}...\")\n",
    "        i += 2\n",
    "    #print(f\"\\n\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def extract_pdf_link_from_unit(unit: str):\n",
    "    \"\"\"\n",
    "    Extract ONE PDF URL from a unit.\n",
    "    - Must start with http:// or https://\n",
    "    - Must end with .pdf\n",
    "    - Allows breaks (space, newline, hyphen)\n",
    "    Returns the first valid PDF or None.\n",
    "    \"\"\"\n",
    "    if not isinstance(unit, str):\n",
    "        return None\n",
    "\n",
    "    raw = unit.replace(\"\\r\", \"\")\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"(https?://(?:[^\\s]|[\\s\\-]){1,1000}?\\.pdf)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    match = pattern.search(raw)\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    # cleaned = match.group(1)\n",
    "    # cleaned = cleaned.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "    # cleaned = cleaned.replace(\"\\t\", \"\").replace(\"\\u00a0\", \"\")\n",
    "    # cleaned = cleaned.replace(\"-/\", \"/\")\n",
    "\n",
    "    return match.group(1)\n",
    "\n",
    "\n",
    "CATEGORY_KEYWORDS = {\n",
    "    \"mandatory_disclosure\": [\"mandatory\", \"mandatory disclosure\", \"mandatory_disclosure\", \"mandatory disclosures\", \"mandatory_disclosures\", \"statutory disclosure\", \"statutory_disclosure\", \"statutory disclosures\", \"statutory_disclosures\", \"aicte mandatory disclosure\", \"aicte_mandatory_disclosure\", \"aicte disclosure\", \"aicte_disclosure\", \"mandatory discloser\", \"mandatory_discloser\", \"mandatory discloure\", \"mandatory_discloure\", \"disclosure\"],\n",
    "\n",
    "    \"naac\": [\"naac\", \"naac accreditation\", \"naac_accreditation\", \"assessment & accreditation\", \"assessment and accreditation\", \"assessment_accreditation\", \"assessment_and_accreditation\", \"ssr\", \"dvv\", \"nacc\", \"qim\", \"qnm\"],\n",
    "\n",
    "    \"nba\": [\"nba\", \"nba accreditation\", \"nba_accreditation\", \"national board of accreditation\", \"national_board_of_accreditation\"],\n",
    "\n",
    "    \"nirf\": [\"nirf\", \"nirf ranking\", \"nirf_ranking\", \"nirf india ranking\", \"nirf_india_ranking\", \"national institutional ranking framework\", \"national_institutional_ranking_framework\"],\n",
    "\n",
    "    \"iqac\": [\"iqac\", \"internal quality assurance cell\", \"internal_quality_assurance_cell\", \"quality assurance cell\", \"quality_assurance_cell\", \"quality assurance committee\", \"quality_assurance_committee\"],\n",
    "\n",
    "    \"aicte\": [\"aicte\", \"all india council for technical education\", \"all_india_council_for_technical_education\", \"aicte approval\", \"aicte_approval\", \"aicte extension of approval\", \"aicte_extension_of_approval\"],\n",
    "\n",
    "    \"aqar\": [\"aqar\", \"annual quality assurance report\", \"annual_quality_assurance_report\"],\n",
    "\n",
    "    \"ariia\": [\"ariia\", \"atal\", \"atal ranking\", \"atal_ranking\", \"atal ranking of institutions on innovation achievements\", \"atal_ranking_of_institutions_on_innovation_achievements\"],\n",
    "\n",
    "    \"accreditation\": [\"accreditation\", \"accredited\", \"accreditations\", \"download\", \"affiliation\",\"placement\"],\n",
    "\n",
    "    \"criteria\": [\"crit\", \"criteria\", \"criterion\", \"criteria1\", \"criteria2\", \"criteria3\", \"criteria4\", \"criteria5\", \"criteria6\", \"criteria7\"],\n",
    "\n",
    "    \"criteria_1\": [\"criteria 1\", \"criteria-1\", \"criteria_1\", \"criterion 1\", \"criterion-1\", \"criterion_1\", \"criterion1\", \"criteria1\"],\n",
    "\n",
    "    \"criteria_2\": [\"criteria 2\", \"criteria-2\", \"criteria_2\", \"criterion 2\", \"criterion-2\", \"criterion_2\", \"criterion2\", \"criteria2\"],\n",
    "\n",
    "    \"criteria_3\": [\"criteria 3\", \"criteria-3\", \"criteria_3\", \"criterion 3\", \"criterion-3\", \"criterion_3\", \"criterion3\", \"criteria3\"],\n",
    "\n",
    "    \"criteria_4\": [\"criteria 4\", \"criteria-4\", \"criteria_4\", \"criterion 4\", \"criterion-4\", \"criterion_4\", \"criterion4\", \"criteria4\"],\n",
    "\n",
    "    \"criteria_5\": [\"criteria 5\", \"criteria-5\", \"criteria_5\", \"criterion 5\", \"criterion-5\", \"criterion_5\", \"criterion5\", \"criteria5\"],\n",
    "\n",
    "    \"criteria_6\": [\"criteria 6\", \"criteria-6\", \"criteria_6\", \"criterion 6\", \"criterion-6\", \"criterion_6\", \"criterion6\", \"criteria6\"],\n",
    "\n",
    "    \"criteria_7\": [\"criteria 7\", \"criteria-7\", \"criteria_7\", \"criterion 7\", \"criterion-7\", \"criterion_7\", \"criterion7\", \"criteria7\"],\n",
    "}\n",
    "\n",
    "def normalize_text_for_match(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize text by:\n",
    "    - lowercasing\n",
    "    - replacing non-alphanumeric characters with '_'\n",
    "    - collapsing multiple '_' into single '_'\n",
    "    - stripping leading/trailing '_'\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9]\", \"_\", text)\n",
    "    text = re.sub(r\"_+\", \"_\", text)\n",
    "    return text.strip(\"_\")\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def normalize_for_year_detection(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Unicode normalization (fixes – — etc.)\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "\n",
    "    # Replace common separators with space\n",
    "    text = re.sub(r\"[._/\\\\\\-–—]+\", \" \", text)\n",
    "\n",
    "    # Remove URL encoding artifacts\n",
    "    text = text.replace(\"%20\", \" \")\n",
    "\n",
    "    # Collapse whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def extract_document_years(text: str) -> list[int]:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    text = normalize_for_year_detection(text)\n",
    "\n",
    "    years = set()\n",
    "\n",
    "    # 1️⃣ Capture standalone years (not embedded in numbers)\n",
    "    for y in re.findall(r\"(?<!\\d)(19\\d{2}|20\\d{2})(?!\\d)\", text):\n",
    "        years.add(int(y))\n",
    "\n",
    "    # 2️⃣ Capture year ranges like 2027-28, 2027/28, 2027–28, 2027_28\n",
    "    for y1, y2 in re.findall(\n",
    "        r\"(?<!\\d)(19\\d{2}|20\\d{2})\\s*[-/–—_]\\s*(\\d{2}|19\\d{2}|20\\d{2})(?!\\d)\",\n",
    "        text\n",
    "    ):\n",
    "        y1 = int(y1)\n",
    "\n",
    "        if len(y2) == 2:\n",
    "            # 2027-28 → 2028\n",
    "            y2 = int(str(y1)[:2] + y2)\n",
    "        else:\n",
    "            y2 = int(y2)\n",
    "\n",
    "        years.add(y1)\n",
    "        years.add(y2)\n",
    "\n",
    "    return sorted(years)\n",
    "\n",
    "\n",
    "def unit_has_old_year(text: str) -> bool:\n",
    "    years = extract_document_years(text)\n",
    "\n",
    "    # Production-safe rule:\n",
    "    # No year → discard\n",
    "    if not years:\n",
    "        return False\n",
    "\n",
    "    # Keep ONLY if at least one year >= 2019\n",
    "    return max(years) < 2019\n",
    "\n",
    "\n",
    "def safe_filename_from_url(url: str, index: int ) -> str:\n",
    "    index = 0 \n",
    "    \"\"\"\n",
    "    Create filename from URL by:\n",
    "    - removing scheme (http/https)\n",
    "    - removing domain\n",
    "    - keeping full path\n",
    "    - making it filesystem-safe\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "\n",
    "    # Take full path without leading slash\n",
    "    path = parsed.path.lstrip(\"/\")\n",
    "\n",
    "    # Fallback safety\n",
    "    if not path.lower().endswith(\".pdf\"):\n",
    "        path = \"document.pdf\"\n",
    "\n",
    "    # Replace path separators and illegal chars\n",
    "    filename = re.sub(r\"[\\\\/]\", \"_\", path)\n",
    "    filename = re.sub(r\"[^\\w.\\-]\", \"_\", filename)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def extract_years(text: str):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return [int(y) for y in re.findall(r\"\\b(19\\d{2}|20\\d{2})\\b\", text)]\n",
    "\n",
    "def normalize_column_name(col: str) -> str:\n",
    "    col = col.lower()\n",
    "    if col.endswith(\"_links\"):\n",
    "        col = col[:-6]\n",
    "    return col\n",
    "\n",
    "\n",
    "def get_target_year_folder(unit_text: str, base_output_dir: str):\n",
    "    years = extract_document_years(unit_text)\n",
    "\n",
    "    if years:\n",
    "        year_folder = str(max(years))\n",
    "    else:\n",
    "        year_folder = \"no_year\"\n",
    "\n",
    "    folder_path = os.path.join(base_output_dir, year_folder)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    return folder_path\n",
    "\n",
    "def nirf_with_innovation_or_management(unit_text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if:\n",
    "    - 'nirf' is present\n",
    "    AND\n",
    "    - innovation OR management is present (any canonical / short form)\n",
    "    \"\"\"\n",
    "    if not isinstance(unit_text, str):\n",
    "        return False\n",
    "\n",
    "    text = normalize_text_for_match(unit_text).lower()\n",
    "\n",
    "    nirf_terms = {\n",
    "        \"nirf\",\n",
    "        \"national_institutional_ranking_framework\"\n",
    "    }\n",
    "\n",
    "    innovation_terms = {\n",
    "        \"innovation\", \n",
    "        \"innv\",\n",
    "\n",
    "    }\n",
    "\n",
    "    management_terms = {\n",
    "        \"management\",\n",
    "        \"mgmt\", \"mgmnt\", \"mgt\",\n",
    "        \"mba\", \"pgdm\",\n",
    "        \"business_administration\"\n",
    "    }\n",
    "\n",
    "    has_nirf = any(term in text for term in nirf_terms)\n",
    "    has_innovation = any(term in text for term in innovation_terms)\n",
    "    has_management = any(term in text for term in management_terms)\n",
    "\n",
    "    return has_nirf and (has_innovation or has_management)\n",
    "\n",
    "\n",
    "ALL_CATEGORY_KEYWORDS = {\n",
    "    normalize_text_for_match(kw.lower())\n",
    "    for keywords in CATEGORY_KEYWORDS.values()\n",
    "    for kw in keywords\n",
    "}\n",
    "\n",
    "def handle_depth_0(cell_value, output_dir, pdf_count):\n",
    "    chunks = split_links_with_text(cell_value)\n",
    "    if not chunks:\n",
    "        return pdf_count\n",
    "\n",
    "    keywords = ALL_CATEGORY_KEYWORDS\n",
    "\n",
    "    matched_chunks = []\n",
    "\n",
    "    for unit in chunks:\n",
    "        normalized_unit = normalize_text_for_match(unit.lower())\n",
    "\n",
    "        if any(kw in normalized_unit for kw in keywords):\n",
    "            matched_chunks.append(unit)\n",
    "        else:\n",
    "            print(f\"[SKIP][NO-KEYWORD-MATCH] {unit[:120]}...\")\n",
    "\n",
    "\n",
    "    if not matched_chunks:\n",
    "        print(f\"[SKIP][DEPTH0][NO-MATCH]\")\n",
    "        return pdf_count\n",
    "\n",
    "    for unit in matched_chunks:\n",
    "        # ✅ NEW: discard NIRF + Innovation / Management\n",
    "        if nirf_with_innovation_or_management(unit):\n",
    "            print(\"[SKIP][NIRF-INNOVATION/MANAGEMENT]\", unit)\n",
    "            continue\n",
    "\n",
    "        link = extract_pdf_link_from_unit(unit)\n",
    "        if not link:\n",
    "            continue\n",
    "\n",
    "        # ✅ UNIT-level year check\n",
    "        if unit_has_old_year(unit) or unit_has_old_year(link):\n",
    "            print(f\"[SKIP][OLD-YEAR] {unit}\")\n",
    "            continue\n",
    "\n",
    "        if link in seen_pdf_urls:\n",
    "            print(f\"[SKIP][DUPLICATE] {link}\")\n",
    "            continue\n",
    "\n",
    "        seen_pdf_urls.add(link)\n",
    "        pdf_count += 1\n",
    "        filename = safe_filename_from_url(link, pdf_count)\n",
    "        #file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # ✅ ADD THIS\n",
    "        target_dir = get_target_year_folder(unit, output_dir)\n",
    "        file_path = os.path.join(target_dir, filename)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"[SKIP] {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"[DOWNLOAD] {link}\")\n",
    "            with requests.get(\n",
    "                link,\n",
    "                headers=HEADERS,\n",
    "                stream=True,\n",
    "                timeout=DOWNLOAD_TIMEOUT\n",
    "            ) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {link} -> {e}\")\n",
    "\n",
    "    return pdf_count\n",
    "\n",
    "\n",
    "def handle_depth_gt_0(cell_value, output_dir, pdf_count):\n",
    "    chunks = split_links_with_text(cell_value)\n",
    "    if not chunks:\n",
    "        return pdf_count\n",
    "\n",
    "    for unit in chunks:\n",
    "\n",
    "        # ✅ NEW: discard NIRF + Innovation / Management\n",
    "        if nirf_with_innovation_or_management(unit):\n",
    "            print(\"[SKIP][NIRF-INNOVATION/MANAGEMENT]\", unit)\n",
    "            continue\n",
    "\n",
    "        link = extract_pdf_link_from_unit(unit)\n",
    "        if not link:\n",
    "            continue\n",
    "\n",
    "        # ✅ UNIT-level year check\n",
    "        if unit_has_old_year(unit) or unit_has_old_year(link):\n",
    "            print(f\"[SKIP][OLD-YEAR] {unit}\")\n",
    "            continue\n",
    "\n",
    "        if link in seen_pdf_urls:\n",
    "            print(f\"[SKIP][DUPLICATE] {link}\")\n",
    "            continue\n",
    "\n",
    "        seen_pdf_urls.add(link)\n",
    "        pdf_count += 1\n",
    "        filename = safe_filename_from_url(link, pdf_count)\n",
    "        #file_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # ✅ ADD THIS\n",
    "        target_dir = get_target_year_folder(unit, output_dir)\n",
    "        file_path = os.path.join(target_dir, filename)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"[SKIP] {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"[DOWNLOAD] {link}\")\n",
    "            with requests.get(\n",
    "                link,\n",
    "                headers=HEADERS,\n",
    "                stream=True,\n",
    "                timeout=DOWNLOAD_TIMEOUT\n",
    "            ) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {link} -> {e}\")\n",
    "\n",
    "    return pdf_count\n",
    "\n",
    "\n",
    "\n",
    "# ================= CORE =================\n",
    "\n",
    "def download_pdfs_from_excel(excel_path):\n",
    "    global seen_pdf_urls\n",
    "    seen_pdf_urls = set()\n",
    "    excel_name = os.path.basename(excel_path)\n",
    "    excel_stem = os.path.splitext(excel_name)[0]\n",
    "\n",
    "    output_dir = os.path.join(\n",
    "        PDF_DOWNLOADS_FOLDER,\n",
    "        f\"pdf_download_{excel_stem}\"\n",
    "    )\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n[INFO] Reading Excel: {excel_path}\")\n",
    "    print(f\"[INFO] Output folder: {output_dir}\")\n",
    "\n",
    "    df = pd.read_excel(excel_path, engine=\"openpyxl\")\n",
    "\n",
    "    if \"row_type\" not in df.columns:\n",
    "        print(\"[WARN] 'row_type' column missing — skipping\")\n",
    "        return\n",
    "\n",
    "    pdf_count = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if str(row.get(\"row_type\", \"\")).strip().lower() != \"pdf\":\n",
    "            continue\n",
    "\n",
    "        depth = int(row.get(\"depth\", -1))\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col in {\"row_type\", \"depth\"}:\n",
    "                continue\n",
    "\n",
    "            cell_value = row[col]\n",
    "\n",
    "            if depth == 0:\n",
    "                #print(f\"[PROCESS][DEPTH {depth}] Column: {col}\")\n",
    "                pdf_count = handle_depth_0(\n",
    "                    cell_value,\n",
    "                    output_dir,\n",
    "                    pdf_count\n",
    "                )\n",
    "            else:\n",
    "                #print(f\"[PROCESS][DEPTH {depth}] Column: {col}\")\n",
    "                pdf_count = handle_depth_gt_0(\n",
    "                    cell_value,\n",
    "                    output_dir,\n",
    "                    pdf_count\n",
    "                )\n",
    "\n",
    "\n",
    "    print(f\"[DONE] PDFs attempted from {excel_name}: {pdf_count}\")\n",
    "\n",
    "# ================= RUN ALL EXCEL FILES =================\n",
    "\n",
    "def run_for_all_excels():\n",
    "    if not os.path.isdir(OUTPUT_COLLEGE_INFO_FOLDER):\n",
    "        raise FileNotFoundError(OUTPUT_COLLEGE_INFO_FOLDER)\n",
    "\n",
    "    excel_files = [\n",
    "        f for f in os.listdir(OUTPUT_COLLEGE_INFO_FOLDER)\n",
    "        if f.lower().endswith(\".xlsx\") and not f.startswith(\"~$\")\n",
    "    ]\n",
    "\n",
    "    if not excel_files:\n",
    "        print(\"[WARN] No Excel files found\")\n",
    "        return\n",
    "\n",
    "    for excel in excel_files:\n",
    "        excel_path = os.path.join(OUTPUT_COLLEGE_INFO_FOLDER, excel)\n",
    "        download_pdfs_from_excel(excel_path)\n",
    "\n",
    "    print(\"\\n[ALL DONE] Processed all Excel files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec12866",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_for_all_excels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_for_all_excels\u001b[49m()\n",
      "\u001b[31mNameError\u001b[39m: name 'run_for_all_excels' is not defined"
     ]
    }
   ],
   "source": [
    "#---------------------final function to run-------------------------------------\n",
    "run_for_all_excels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Reading Excel: output_college_info/college_info_pallavi_engineering_college.xlsx\n",
      "[INFO] Output folder: pdf_downloads/pdf_download_college_info_pallavi_engineering_college\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/nirf/PEC NIRF-2025 Engineering 19691.pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/nirf/PEC NIRF-2025 Innovation 19691.pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/nirf/PEC NIRF-2025 Management 19691.pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/nirf/PEC NIRF-2025 Overall 19691.pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/assets/img/facilities/eoreport.pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/admissions/PallaviBseats.pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/assets/docs/HolidaysList.pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/mondatory-disclosure.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2023/02/IITB_IITKGP_Workshops.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2023/03/TSCOGN104995%20(2).pdf\n",
      "[DOWNLOAD] https://pallaviengineeringcollege.ac.in/wp-content/uploads/2024/5/NIRF-2024.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2023/02/All%20Report-MHRD,%20National%20Institutional%20Ranking%20Framework%20(NIRF).pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2023/02/pec-nirf-report%202019-20.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in//wp-content/uploads/2022/12/4.1.1-5%20Gym%20Activities.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/old_website_31_10/wp-content/uploads/2022/12/6.5.1.Internal%20Quality%20Assurance%20Cell%20(IQAC).pdf\n",
      "[ERROR] https://www.pallaviengineeringcollege.ac.in/old_website_31_10/wp-content/uploads/2022/12/6.5.1.Internal%20Quality%20Assurance%20Cell%20(IQAC).pdf -> 404 Client Error: Not Found for url: https://www.pallaviengineeringcollege.ac.in/old_website_31_10/wp-content/uploads/2022/12/6.5.1.Internal%20Quality%20Assurance%20Cell%20(IQAC).pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2022/12/4.1.1-1%20LAND%20DOCUEMNT%205%20ACRES%205%20ACRES%20COLOUR.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2022/12/4.1.1-2%20BUILDING%20PLAN.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2022/12/4.1.1-3%20Infrastructure-%20Physical%20facilities%20-ICT.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2022/12/4.1.1-4%20Cultural%20Activities.pdf\n",
      "[DOWNLOAD] https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2022/12/4.1.1-6%20Yoga%20Activities.pdf\n",
      "[DONE] PDFs attempted from college_info_pallavi_engineering_college.xlsx: 20\n"
     ]
    }
   ],
   "source": [
    "#download_pdfs_from_excel(\"output_college_info/college_info_96_Abacus_Institute_Of_Engineering_And_Management.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
