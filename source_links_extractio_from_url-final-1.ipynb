{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da74854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Full script with requested updates>\n",
    "\n",
    "# Complete integrated scraper with screenshot-on-failure and robust click handling.\n",
    "# Paste into one Jupyter cell and run. Then call `df = await run_scraping(example)` in another cell.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set\n",
    "from urllib.parse import (\n",
    "    urlparse, urljoin, urlunparse, parse_qsl, urlencode, unquote\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from playwright.async_api import (\n",
    "    async_playwright,\n",
    "    Page,\n",
    "    Error as PlaywrightError,\n",
    "    TimeoutError as PlaywrightTimeoutError,\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------- CONFIG -------------------------\n",
    "\n",
    "HEADLESS = True\n",
    "PAGE_LOAD_TIMEOUT = 60000\n",
    "EXTRA_WAIT_MS = 2000\n",
    "\n",
    "OUTPUT_EXCEL = \"accreditation_links_2_0_copy_copy.xlsx\"\n",
    "EXCEL_INPUT_FILE = \"MAKAUT_AffiliatedCollege_List.xlsx\"\n",
    "SHEET_NAME = \"Sheet1\"\n",
    "\n",
    "# ------------------------- GLOBAL EXECUTION CONTEXT -------------------------\n",
    "\n",
    "CURRENT_COLLEGE_CONTEXT = {\n",
    "    \"college_name\": None,\n",
    "    \"url\": None,\n",
    "}\n",
    "\n",
    "# ------------------------- KEYWORDS (UPDATED) -------------------------\n",
    "CATEGORY_KEYWORDS = {\n",
    "    \"mandatory_disclosure\": [\n",
    "        \"mandatory disclosure\", \"mandatory disclosures\",\n",
    "        \"statutory disclosure\", \"statutory disclosures\",\n",
    "        \"aicte mandatory disclosure\", \"aicte disclosure\",\n",
    "        \"mandatory discloser\", \"mandatory discloure\",\n",
    "        \"disclosure\",\n",
    "    ],\n",
    "    \"naac\": [\n",
    "        \"naac\", \"assessment & accreditation\", \"assessment and accreditation\",\n",
    "        \"naac accreditation\",\"ssr\",\"dvv\",\"nacc\",\"qim\",\"qnm\",\"nacc\"\n",
    "    ],\n",
    "    \"nba\": [\n",
    "        \"nba\", \"national board of accreditation\",\n",
    "        \"nba accreditation\",\n",
    "    ],\n",
    "    \"nirf\": [\n",
    "        \"nirf\", \"national institutional ranking framework\", \"nirf ranking\",\n",
    "        \"nirf india ranking\",\n",
    "    ],\n",
    "    \"iqac\": [\n",
    "        \"iqac\", \"internal quality assurance cell\",\n",
    "        \"quality assurance cell\", \"quality assurance committee\",\n",
    "    ],\n",
    "    \"aicte\": [\n",
    "        \"aicte\", \"all india council for technical education\",\n",
    "        \"aicte approval\", \"aicte extension of approval\",\n",
    "    ],\n",
    "    \"aqar\": [\n",
    "        \"aqar\", \"annual quality assurance report\",\n",
    "    ],\n",
    "    \"ariia\": [\n",
    "        \"ariia\", \"atal ranking\",\"atal ranking of institutions on innovation achievements\", \"atal\"\n",
    "    ],\n",
    "    \"accreditation\": [\n",
    "        \"accreditation\", \"accredited\", \"accreditations\", \"download\",\"affiliation\"\n",
    "    ],\n",
    "    # explicit criteria category\n",
    "    \"criteria\": [\n",
    "        \"crit\",\"criteria\", \"criteria1\", \"criteria2\", \"criteria3\", \"criteria4\", \"criteria5\", \"criteria6\", \"criteria7\"\n",
    "\n",
    "    ],\n",
    "    \"criteria_1\": [\"criteria-1\", \"criteria 1\", \"criterion 1\",\"criterion1\",\"criteria1\",\"criterion-1\",\"1.2.1\",\"1.2.2\",\"1.3.2\",\"1.4.1\"],\n",
    "    \"criteria_2\": [\"criteria-2\", \"criteria 2\", \"criterion 2\",\"criterion2\",\"criteria2\",\"criterion-2\",\"2.1.1\",\"2.1.2\",\"2.2.1\",\"2.4.1\",\"2.4.2\",\"2.6.3\"],\n",
    "    \"criteria_3\": [\"criteria-3\", \"criteria 3\", \"criterion 3\",\"criterion3\",\"criteria3\",\"criterion-3\",\"3.1.1\",\"3.2.2\",\"3.3.1\",\"3.3.2\",'3.4.3',\"3.5.1\"],\n",
    "    \"criteria_4\": [\"criteria-4\", \"criteria 4\", \"criterion 4\",\"criterion4\",\"criteria4\",\"criterion-4\",\"4.1.2\",\"4.3.2\",\"4.4.1\"],\n",
    "    \"criteria_5\": [\"criteria-5\", \"criteria 5\", \"criterion 5\",\"criterion5\",\"criteria5\",\"criterion-5\",\"5.1.1\",\"5.2.1\",\"5.1.3\",\"5.1.4\",\"5.2.1\",\"5.2.2\",\"5.3.1\",\"5.3.2\"],\n",
    "    \"criteria_6\": [\"criteria-6\", \"criteria 6\", \"criterion 6\",\"criterion6\",\"criteria6\",\"criterion-6\",\"6.2.2\",\"6.3.2\",\"6.3.3\",\"6.5.2\"],\n",
    "    \"criteria_7\": [\"criteria-7\", \"criteria 7\", \"criterion 7\",\"criterion7\",\"criteria7\",\"criterion-7\",\"7.1.2\",\"7.1.3\"],\n",
    "}\n",
    "CRITERION_METRIC_REGEX = re.compile(\n",
    "    r\"\"\"\n",
    "    (?:\n",
    "        \\b([1-7])\\.\\d+\\.\\d+\\b |          # 2.6.3 , 7.1.11\n",
    "        \\b([1-7])[\\-_ ]\\d+[\\-_ ]\\d+\\b |  # 2-6-3 , 2_6_3\n",
    "        \\b([1-7])\\.\\d+\\b |               # 2.6 (key indicator)\n",
    "        metric\\s*[-:]?\\s*(\\d{3,4}) |     # Metric 263 / 7211\n",
    "        criterion\\s*[-‚Äì]?\\s*(i{1,3}|iv|v|vi|vii)  # Criterion IV\n",
    "    )\n",
    "    \"\"\",\n",
    "    re.IGNORECASE | re.VERBOSE\n",
    ")\n",
    "\n",
    "ROMAN_TO_INT = {\n",
    "    \"i\":1,\"ii\":2,\"iii\":3,\"iv\":4,\n",
    "    \"v\":5,\"vi\":6,\"vii\":7\n",
    "}\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"output_college_info_6_7\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ERROR_LOG_FILE = OUTPUT_DIR / \"failed_colleges_errors.log\"\n",
    "\n",
    "def log_college_error(college_name: str, base_url: str, exc: Exception):\n",
    "    \"\"\"\n",
    "    Append any college-level error to a persistent log file.\n",
    "    Never raises.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(ERROR_LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "            f.write(f\"TIMESTAMP : {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"COLLEGE   : {college_name}\\n\")\n",
    "            f.write(f\"BASE URL  : {base_url}\\n\")\n",
    "            f.write(\"ERROR     :\\n\")\n",
    "            f.write(\"\".join(traceback.format_exception(type(exc), exc, exc.__traceback__)))\n",
    "            f.write(\"\\n\")\n",
    "    except Exception:\n",
    "        # Logging must NEVER break execution\n",
    "        pass\n",
    "\n",
    "\n",
    "def infer_criteria_column(text: str, url: str) -> str | None:\n",
    "    combined = f\"{text} {url}\".lower()\n",
    "    m = CRITERION_METRIC_REGEX.search(combined)\n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    # Roman numerals\n",
    "    for r, v in ROMAN_TO_INT.items():\n",
    "        if r in m.group(0).lower():\n",
    "            return f\"criteria_{v}\"\n",
    "\n",
    "    # Numeric cases\n",
    "    digit = re.search(r\"[1-7]\", m.group(0))\n",
    "    if digit:\n",
    "        return f\"criteria_{digit.group()}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "IQAC_ADMIN_SUBSTRINGS = (\n",
    "    # governance\n",
    "    \"committ\", \"member\", \"compos\", \"struct\",\n",
    "    \"chair\", \"coordin\", \"authorit\", \"power\", \"duti\",\"strateg\",\n",
    "\n",
    "    # philosophy / intent\n",
    "    \"vision\", \"mission\", \"object\", \"goal\",\n",
    "\n",
    "    # planning / monitoring\n",
    "    \"plan\", \"monitor\", \"evaluat\",\n",
    "\n",
    "    # functions / operations\n",
    "    \"function\", \"activ\", \"process\", \"mechan\",\n",
    "\n",
    "    # quality language\n",
    "    \"enhanc\", \"improv\",\n",
    "\n",
    "    # policies / systems\n",
    "    \"framework\", \"internal\",\n",
    "\n",
    "    # feedback / stakeholders\n",
    "    \"stakehold\",\n",
    "\n",
    "    # meetings / records (non-doc)\n",
    "    \"minute\", \"meet\",\n",
    "\n",
    "    # events / training\n",
    "    \"workshop\", \"seminar\", \"training\",\"benefit\",\"development\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "def setup_asyncio_exception_logger():\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    def handle_async_exception(loop, context):\n",
    "        exc = context.get(\"exception\")\n",
    "        msg = context.get(\"message\", \"Async exception occurred\")\n",
    "\n",
    "        college = CURRENT_COLLEGE_CONTEXT.get(\"college_name\")\n",
    "        url = CURRENT_COLLEGE_CONTEXT.get(\"url\")\n",
    "\n",
    "        try:\n",
    "            with open(ERROR_LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "                f.write(f\"TIMESTAMP : {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"COLLEGE   : {college or 'UNKNOWN'}\\n\")\n",
    "                f.write(f\"URL       : {url or 'UNKNOWN'}\\n\")\n",
    "                f.write(\"ASYNC ERROR:\\n\")\n",
    "                f.write(msg + \"\\n\")\n",
    "\n",
    "                if exc:\n",
    "                    f.write(\n",
    "                        \"\".join(\n",
    "                            traceback.format_exception(\n",
    "                                type(exc), exc, exc.__traceback__\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "        except Exception:\n",
    "            pass  # logging must never break execution\n",
    "\n",
    "    loop.set_exception_handler(handle_async_exception)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "NAAC_INTERNAL_KEYWORDS = [\n",
    "    \"iqac\",\n",
    "    \"iiqa\",\n",
    "    \"ssr\",\n",
    "    \"dvv\",\n",
    "    \"qif\",\n",
    "    \"quality indicator framework\",\n",
    "    \"extended profile\",\n",
    "    \"criterion\",\n",
    "    \"criteria\",\n",
    "    \"metric\",\n",
    "    \"cycle\",\n",
    "]\n",
    "'''\n",
    "'''\n",
    "NAVIGATION_KEYWORDS = [\n",
    "    \"naac\", \"nba\", \"nirf\", \"iqac\",\n",
    "    \"mandatory\", \"disclosure\", \"accreditation\", \"ariia\", \"ranking\",\n",
    "    \"quality\", \"aicte\", \"aqar\", \"annual quality assurance\",\n",
    "]\n",
    "\n",
    "INTERESTING_KEYWORDS_IN_URL = [\n",
    "    \"naac\", \"nba\", \"nirf\", \"aicte\", \"aqar\",\n",
    "    \"accreditation\", \"accreditations\", \"accredited\",\n",
    "    \"approval\", \"approvals\", \"extension-of-approval\",\n",
    "    \"mandatory\", \"disclosure\", \"disclosures\", \"statutory\",\n",
    "    \"iqac\", \"internal-quality-assurance\", \"quality-assurance\",\n",
    "    \"annual-quality-assurance-report\", \"annual-report\",\n",
    "    \"aqar\", \"report\", \"reports\",\n",
    "    \"ariia\", \"atal-ranking\", \"innovation-ranking\",\n",
    "    \"link \", \"links \", \"quick-link\", \"quick-links\", \"quick links\",\n",
    "    \"useful-links\", \"important-links\",\n",
    "    \"download\", \"downloads\", \"forms\", \"notices\", \"notice\",\n",
    "    \"circular\", \"circulars\", \"document\", \"documents\",\n",
    "    \"ranking\", \"nirf-ranking\", \"nirf-india-ranking\",\n",
    "    \"certificate\", \"certificates\", \"approval-letter\",\n",
    "    \"brochure\", \"prospectus\", \"placement\", \"placements\",\n",
    "    \"fee-structure\", \"fees\",\n",
    "]\n",
    "'''\n",
    "# ------------------------- GLOBAL STATE -------------------------\n",
    "PROGRESS_ROWS = {}\n",
    "#GLOBAL_URL_OWNERS = {}\n",
    "GLOBAL_SEEN_URLS = set()\n",
    "GLOBAL_SEEN_ARTIFACTS = set()   # typed dedupe keys\n",
    "GLOBAL_SEEN_PAGES = set()      # raw normalized page URLs\n",
    "\n",
    "GLOBAL_EXCEL_URLS = set()\n",
    "GLOBAL_BFS_URLS = set()\n",
    "\n",
    "\n",
    "def should_accept_context(existing: str | None, new: str) -> bool:\n",
    "    if existing is None:\n",
    "        return True\n",
    "\n",
    "    existing = existing.strip().lower()\n",
    "    if existing in (\"\", \"network pdf\", \"pdf document\", \"iframe pdf\"):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# ------------------------- URL NORMALIZATION / HELPERS -------------------------\n",
    "'''\n",
    "async def reveal_hidden_dom(page):\n",
    "    \"\"\"\n",
    "    Click elements that ONLY reveal DOM (menus, accordions),\n",
    "    NOT expecting PDFs.\n",
    "    \"\"\"\n",
    "    revealers = page.locator(\n",
    "        '[data-bs-toggle=\"collapse\"],'\n",
    "        '[aria-expanded=\"false\"],'\n",
    "        'details > summary'\n",
    "    )\n",
    "\n",
    "    for i in range(await revealers.count()):\n",
    "        el = revealers.nth(i)\n",
    "        try:\n",
    "            fingerprint = await get_element_fingerprint(el)\n",
    "            if fingerprint in page._clicked_elements:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                if not await el.is_visible():\n",
    "                    continue\n",
    "                await el.scroll_into_view_if_needed(timeout=1500)\n",
    "                await el.click(timeout=1500)\n",
    "                await safe_load_wait(page)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "\n",
    "            page._clicked_elements.add(fingerprint)\n",
    "            await page.wait_for_timeout(300)\n",
    "        except Exception:\n",
    "            continue\n",
    "'''\n",
    "\n",
    "TRACKING_PARAMS = {\n",
    "    \"utm_source\", \"utm_medium\", \"utm_campaign\", \"utm_term\", \"utm_content\",\n",
    "    \"fbclid\", \"gclid\", \"mc_cid\", \"mc_eid\"\n",
    "}\n",
    "\n",
    "def is_iqac_admin_page(combined: str) -> bool:\n",
    "    combined = combined.lower()\n",
    "\n",
    "    if \"iqac\" not in combined:\n",
    "        return False\n",
    "\n",
    "    iqac_pos = combined.find(\"iqac\")\n",
    "\n",
    "    for sub in IQAC_ADMIN_SUBSTRINGS:\n",
    "        sub_pos = combined.find(sub)\n",
    "\n",
    "        if sub_pos != -1 and abs(sub_pos - iqac_pos) < 50:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize_url(url: str, text: str = \"\") -> str:\n",
    "    if not url:\n",
    "        return url\n",
    "    try:\n",
    "        p = urlparse(url)\n",
    "    except Exception:\n",
    "        return url\n",
    "\n",
    "    # üîí Force HTTPS to avoid http/https duplicates\n",
    "    scheme = p.scheme or \"http\"\n",
    "\n",
    "    # üîí Normalize domain\n",
    "    netloc = (p.netloc or \"\").lower().lstrip(\"www.\")\n",
    "\n",
    "    path = p.path or \"/\"\n",
    "\n",
    "    # üîí Collapse multiple slashes\n",
    "    while \"//\" in path:\n",
    "        path = path.replace(\"//\", \"/\")\n",
    "\n",
    "    # üîí Remove trailing slash except root\n",
    "    if path.endswith(\"/\") and path != \"/\":\n",
    "        path = path.rstrip(\"/\")\n",
    "\n",
    "    try:\n",
    "        qs = parse_qsl(p.query, keep_blank_values=True)\n",
    "        qs = [(k, v) for (k, v) in qs if k not in TRACKING_PARAMS]\n",
    "        qs.sort()\n",
    "        query = urlencode(qs, doseq=True)\n",
    "    except Exception:\n",
    "        query = \"\"\n",
    "\n",
    "    return urlunparse((\n",
    "        scheme,\n",
    "        netloc,\n",
    "        path,\n",
    "        \"\",      # params\n",
    "        query,\n",
    "        \"\"       # fragment\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "def canonicalize_for_dedupe(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Canonical URL used ONLY for deduplication (BFS + Excel).\n",
    "    \n",
    "    Rule:\n",
    "    - Normalize URL\n",
    "    - If path ends with .php AND there is NO query string ‚Üí strip .php\n",
    "    - If query string exists ‚Üí DO NOT strip .php\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return url\n",
    "\n",
    "    norm = normalize_url(url, \"\")\n",
    "\n",
    "    try:\n",
    "        p = urlparse(norm)\n",
    "\n",
    "        # üîí If query parameters exist ‚Üí do NOT collapse\n",
    "        if p.query:\n",
    "            return norm\n",
    "\n",
    "        path = p.path or \"\"\n",
    "\n",
    "        # üîí Collapse ONLY pure .php endings\n",
    "        if path.lower().endswith(\".php\"):\n",
    "            path = path[:-4] or \"/\"\n",
    "\n",
    "        return urlunparse((\n",
    "            \"https\",                 # üîí force single scheme\n",
    "            p.netloc,\n",
    "            path,\n",
    "            \"\",\n",
    "            \"\",\n",
    "            \"\"\n",
    "        ))\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        return norm\n",
    "\n",
    "\n",
    "def make_dedupe_key(url: str, bucket: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Dedupe must depend on semantic type.\n",
    "    bucket: 'pdf' | 'nonpdf' | None\n",
    "    \"\"\"\n",
    "    norm = normalize_url(url, \"\")\n",
    "    if bucket:\n",
    "        return f\"{bucket}::{norm}\"\n",
    "    return norm\n",
    "\n",
    "def is_same_domain(base_url: str, target_url: str) -> bool:\n",
    "    try:\n",
    "        base = urlparse(base_url)\n",
    "        target = urlparse(target_url)\n",
    "        base_netloc = base.netloc.lower().lstrip(\"www.\")\n",
    "        target_netloc = target.netloc.lower().lstrip(\"www.\")\n",
    "\n",
    "        return target_netloc == \"\" or target_netloc == base_netloc\n",
    "    except Exception:\n",
    "        return False\n",
    "'''\n",
    "def claim_url_once(url: str, text: str, category: str, depth: int) -> bool:\n",
    "    norm = normalize_url(url, \"\")\n",
    "    if norm in GLOBAL_URL_OWNERS:\n",
    "        return False  # ‚ùå already owned ‚Üí do nothing\n",
    "\n",
    "    GLOBAL_URL_OWNERS[norm] = {\n",
    "        \"category\": category,\n",
    "        \"text\": text,\n",
    "        \"depth\": depth,\n",
    "        \"is_pdf\": is_pdf(url)\n",
    "    }\n",
    "    return True\n",
    "\n",
    "\n",
    "def should_follow_link(text: str, href: str) -> bool:\n",
    "    combined = ((text or \"\") + \" \" + (href or \"\")).lower()\n",
    "    return any(kw in combined for kw in NAVIGATION_KEYWORDS)\n",
    "'''\n",
    "def is_interesting_url(url: str, text: str = \"\") -> bool:\n",
    "    if not url:\n",
    "        return False\n",
    "    url_stripped = url.strip()\n",
    "    if url_stripped.startswith((\"javascript:\", \"mailto:\", \"tel:\", \"#\")):\n",
    "        return False\n",
    "    parsed = urlparse(url_stripped)\n",
    "    if parsed.scheme not in (\"http\", \"https\"):\n",
    "        return False\n",
    "    return True\n",
    "'''\n",
    "def url_matches_keywords(url: str, text: str = \"\") -> bool:\n",
    "    if not url and not text:\n",
    "        return False\n",
    "    combined = ((url or \"\") + \" \" + (text or \"\")).lower()\n",
    "    for kws in CATEGORY_KEYWORDS.values():\n",
    "        for kw in kws:\n",
    "            if kw and kw.lower() in combined:\n",
    "                return True\n",
    "    for kw in INTERESTING_KEYWORDS_IN_URL:\n",
    "        if kw.lower() in combined:\n",
    "            return True\n",
    "    return False\n",
    "'''\n",
    "# ------------------------- CONTEXT HELPER (RETAINED) -------------------------\n",
    "# Original combined getter replaced with a getter that returns both own_text and parent_heading separately.\n",
    "'''\n",
    "def accept_url(norm_url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Global BFS-level dedupe.\n",
    "    Raw URLs are never touched here.\n",
    "    \"\"\"\n",
    "    if norm_url in GLOBAL_SEEN_URLS:\n",
    "        return False\n",
    "    GLOBAL_SEEN_URLS.add(norm_url)\n",
    "    return True\n",
    "\n",
    "def accept_url(dedupe_key: str) -> bool:\n",
    "    if dedupe_key in GLOBAL_SEEN_URLS:\n",
    "        return False\n",
    "    GLOBAL_SEEN_URLS.add(dedupe_key)\n",
    "    return True\n",
    "''' \n",
    "def accept_url(dedupe_key: str) -> bool:\n",
    "    if dedupe_key in GLOBAL_SEEN_ARTIFACTS:\n",
    "        return False\n",
    "    GLOBAL_SEEN_ARTIFACTS.add(dedupe_key)\n",
    "    return True\n",
    "\n",
    "\n",
    "def detect_criteria_category(text: str, url: str):\n",
    "    combined = f\"{text} {url}\".lower()\n",
    "\n",
    "    for i in range(1, 8):\n",
    "        if re.search(rf\"\\b(criteria|criterion)[\\s\\-]*{i}\\b\", combined):\n",
    "            return f\"criteria_{i}\"\n",
    "\n",
    "    if \"criteria\" in combined or \"criterion\" in combined:\n",
    "        return \"criteria\"\n",
    "\n",
    "    return None\n",
    "\n",
    "GET_ELEMENT_OWN_AND_PARENT_JS = r\"\"\"\n",
    "(el) => {\n",
    "\n",
    "    function safeText(n) {\n",
    "        try {\n",
    "            return (\n",
    "                typeof n?.innerText === 'string'\n",
    "                    ? n.innerText\n",
    "                    : (n?.textContent || '')\n",
    "            ).trim();\n",
    "        } catch (e) {\n",
    "            return '';\n",
    "        }\n",
    "    }\n",
    "\n",
    "    function safeClass(n) {\n",
    "        try {\n",
    "            if (typeof n?.className === 'string') return n.className.toLowerCase();\n",
    "            if (n?.className && typeof n.className.baseVal === 'string')\n",
    "                return n.className.baseVal.toLowerCase();\n",
    "        } catch (e) {}\n",
    "        return '';\n",
    "    }\n",
    "\n",
    "    function safeTag(n) {\n",
    "        try {\n",
    "            return n?.tagName ? n.tagName.toUpperCase() : '';\n",
    "        } catch (e) {\n",
    "            return '';\n",
    "        }\n",
    "    }\n",
    "\n",
    "    function findHeading(e) {\n",
    "        let p = e;\n",
    "\n",
    "        // üîç walk up parents (guarded)\n",
    "        for (let depth = 0; depth < 5 && p; depth++) {\n",
    "            const tag = safeTag(p);\n",
    "            if (/H[1-6]/.test(tag)) {\n",
    "                const txt = safeText(p);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "\n",
    "            const cls = safeClass(p);\n",
    "            if (\n",
    "                cls &&\n",
    "                (\n",
    "                    cls.includes('title') ||\n",
    "                    cls.includes('heading') ||\n",
    "                    cls.includes('section') ||\n",
    "                    cls.includes('content') ||\n",
    "                    cls.includes('course') ||\n",
    "                    cls.includes('post')\n",
    "                )\n",
    "            ) {\n",
    "                const txt = safeText(p);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "\n",
    "            if (p.getAttribute) {\n",
    "                const aria = (p.getAttribute('aria-label') || '').trim();\n",
    "                if (aria) return aria;\n",
    "            }\n",
    "\n",
    "            p = p.parentElement;\n",
    "        }\n",
    "\n",
    "        // üîç previous siblings\n",
    "        let s = e;\n",
    "        for (let i = 0; i < 5 && s; i++) {\n",
    "            s = s.previousElementSibling;\n",
    "            if (!s) break;\n",
    "\n",
    "            const tag2 = safeTag(s);\n",
    "            if (/H[1-6]/.test(tag2)) {\n",
    "                const txt = safeText(s);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "\n",
    "            const cls2 = safeClass(s);\n",
    "            if (\n",
    "                cls2 &&\n",
    "                (\n",
    "                    cls2.includes('title') ||\n",
    "                    cls2.includes('heading') ||\n",
    "                    cls2.includes('section') ||\n",
    "                    cls2.includes('content') ||\n",
    "                    cls2.includes('course') ||\n",
    "                    cls2.includes('post')\n",
    "                )\n",
    "            ) {\n",
    "                const txt = safeText(s);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return '';\n",
    "    }\n",
    "\n",
    "    function getOwnText(el) {\n",
    "        try {\n",
    "            const own = safeText(el);\n",
    "            if (own) return own;\n",
    "\n",
    "            if (el.getAttribute) {\n",
    "                const title = (el.getAttribute('title') || '').trim();\n",
    "                if (title) return title;\n",
    "\n",
    "                const aria = (el.getAttribute('aria-label') || '').trim();\n",
    "                if (aria) return aria;\n",
    "\n",
    "                const alt = (el.getAttribute('alt') || '').trim();\n",
    "                if (alt) return alt;\n",
    "\n",
    "                const href = el.getAttribute('href');\n",
    "                if (href) {\n",
    "                    try {\n",
    "                        const seg = href.split('/').pop();\n",
    "                        if (seg)\n",
    "                            return decodeURIComponent(seg)\n",
    "                                .replace(/\\+|%20/g, ' ')\n",
    "                                .trim();\n",
    "                    } catch (e) {}\n",
    "                }\n",
    "            }\n",
    "\n",
    "            return '';\n",
    "        } catch (e) {\n",
    "            return '';\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try {\n",
    "        const own = getOwnText(el);\n",
    "        const heading = findHeading(el);\n",
    "        return {\n",
    "            own: own || '',\n",
    "            heading: heading || ''\n",
    "        };\n",
    "    } catch (e) {\n",
    "        return { own: '', heading: '' };\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def get_element_own_and_parent(elem):\n",
    "    try:\n",
    "        res = await safe_elem_evaluate(\n",
    "            elem,\n",
    "            GET_ELEMENT_OWN_AND_PARENT_JS,\n",
    "            default={}\n",
    "        )\n",
    "        if not isinstance(res, dict):\n",
    "            return \"\", \"\"\n",
    "        return (res.get(\"own\", \"\") or \"\").strip(), (res.get(\"heading\", \"\") or \"\").strip()\n",
    "    except Exception:\n",
    "        try:\n",
    "            own = await elem.inner_text()\n",
    "            return (own or \"\").strip(), \"\"\n",
    "        except Exception:\n",
    "            return \"\", \"\"\n",
    "        \n",
    "async def get_element_fingerprint(elem):\n",
    "    try:\n",
    "        return await safe_elem_evaluate(\n",
    "            elem,\n",
    "            \"\"\"\n",
    "            el => {\n",
    "                const role = el.getAttribute('role') || '';\n",
    "                const aria = el.getAttribute('aria-label') || '';\n",
    "                const txt = (\n",
    "                    typeof el.innerText === 'string'\n",
    "                        ? el.innerText\n",
    "                        : (el.textContent || '')\n",
    "                ).trim().slice(0, 50);\n",
    "\n",
    "                const path = [];\n",
    "                let p = el;\n",
    "                let depth = 0;\n",
    "                while (p && depth < 3) {\n",
    "                    path.push(p.tagName + '.' + (p.className || ''));\n",
    "                    p = p.parentElement;\n",
    "                    depth++;\n",
    "                }\n",
    "                return [role, aria, txt, path.join('>')].join('|');\n",
    "            }\n",
    "            \"\"\",\n",
    "            default = None\n",
    "        )\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# ------------------------- CLICK-BASED DISCOVERY (PATCHED to attach keyword/text) -------------------------\n",
    "\n",
    "CLICK_KEYWORDS = [\n",
    "    \"naac\", \"nba\", \"nirf\", \"aicte\", \"aqar\", \"ariia\",\n",
    "    \"accreditation\", \"accredited\",\n",
    "    \"accreditations\", \"certificate\",\n",
    "    \"mandatory\", \"disclosure\", \"iqac\",\n",
    "    \"download\", \"downloads\", \"links\", \"quick links\",\n",
    "]\n",
    "\n",
    "GET_ELEMENT_CONTEXT_JS = r\"\"\"\n",
    "(el) => {\n",
    "\n",
    "    function safeText(n) {\n",
    "        try {\n",
    "            return (\n",
    "                typeof n?.innerText === 'string'\n",
    "                    ? n.innerText\n",
    "                    : (n?.textContent || '')\n",
    "            ).trim();\n",
    "        } catch (e) {\n",
    "            return '';\n",
    "        }\n",
    "    }\n",
    "\n",
    "    function safeClass(n) {\n",
    "        try {\n",
    "            if (typeof n?.className === 'string') return n.className.toLowerCase();\n",
    "            if (n?.className && typeof n.className.baseVal === 'string')\n",
    "                return n.className.baseVal.toLowerCase();\n",
    "        } catch (e) {}\n",
    "        return '';\n",
    "    }\n",
    "\n",
    "    function safeTag(n) {\n",
    "        try {\n",
    "            return n?.tagName ? n.tagName.toUpperCase() : '';\n",
    "        } catch (e) {\n",
    "            return '';\n",
    "        }\n",
    "    }\n",
    "\n",
    "    function findHeading(e) {\n",
    "        let p = e;\n",
    "\n",
    "        // üîç walk up parents\n",
    "        for (let depth = 0; depth < 5 && p; depth++) {\n",
    "            const tag = safeTag(p);\n",
    "            if (/H[1-6]/.test(tag)) {\n",
    "                const txt = safeText(p);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "\n",
    "            const cls = safeClass(p);\n",
    "            if (\n",
    "                cls &&\n",
    "                (\n",
    "                    cls.includes('title') ||\n",
    "                    cls.includes('heading') ||\n",
    "                    cls.includes('section') ||\n",
    "                    cls.includes('content') ||\n",
    "                    cls.includes('course') ||\n",
    "                    cls.includes('post')\n",
    "                )\n",
    "            ) {\n",
    "                const txt = safeText(p);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "\n",
    "            if (p.getAttribute) {\n",
    "                const aria = (p.getAttribute('aria-label') || '').trim();\n",
    "                if (aria) return aria;\n",
    "            }\n",
    "\n",
    "            p = p.parentElement;\n",
    "        }\n",
    "\n",
    "        // üîç previous siblings\n",
    "        let s = e;\n",
    "        for (let i = 0; i < 10 && s; i++) {\n",
    "            s = s.previousElementSibling;\n",
    "            if (!s) break;\n",
    "\n",
    "            const tag2 = safeTag(s);\n",
    "            if (/H[1-6]/.test(tag2)) {\n",
    "                const txt = safeText(s);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "\n",
    "            const cls2 = safeClass(s);\n",
    "            if (\n",
    "                cls2 &&\n",
    "                (\n",
    "                    cls2.includes('title') ||\n",
    "                    cls2.includes('heading') ||\n",
    "                    cls2.includes('section') ||\n",
    "                    cls2.includes('content') ||\n",
    "                    cls2.includes('course') ||\n",
    "                    cls2.includes('post')\n",
    "                )\n",
    "            ) {\n",
    "                const txt = safeText(s);\n",
    "                if (txt) return txt;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return '';\n",
    "    }\n",
    "\n",
    "    try {\n",
    "        const own = safeText(el);\n",
    "        const heading = findHeading(el);\n",
    "\n",
    "        if (heading && own) return (heading + ' ' + own).trim();\n",
    "        if (heading) return heading;\n",
    "        return own;\n",
    "    } catch (e) {\n",
    "        try {\n",
    "            return safeText(el);\n",
    "        } catch (e2) {\n",
    "            return '';\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def get_element_context_text(elem):\n",
    "    \"\"\"\n",
    "    Return the combined heading + element text for a Playwright element handle (locator.nth(i)).\n",
    "    Falls back to element.inner_text() if evaluation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        txt = await safe_elem_evaluate(elem, GET_ELEMENT_CONTEXT_JS, default=\"\")\n",
    "        return (txt or \"\").strip()\n",
    "    except Exception:\n",
    "        try:\n",
    "            return (await elem.inner_text()).strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "NON_CRAWLABLE_EXTENSIONS = (\n",
    "    \".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\", \".bmp\", \".svg\",\n",
    "    \".ico\",\n",
    "    \".mp4\", \".webm\", \".avi\", \".mov\", \".mkv\",\n",
    "    \".mp3\", \".wav\", \".ogg\",\n",
    "    \".zip\", \".rar\", \".7z\", \".tar\", \".gz\",\n",
    "    \".xlsx\", \".xls\", \".csv\", \".ods\" \n",
    ")\n",
    "\n",
    "def is_non_crawlable_url(url: str) -> bool:\n",
    "    if not url:\n",
    "        return True\n",
    "    clean = url.lower().split(\"?\", 1)[0].split(\"#\", 1)[0]\n",
    "    return clean.endswith(NON_CRAWLABLE_EXTENSIONS)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------- DOM URL COLLECT -------------------------\n",
    "async def collect_dom_urls(page):\n",
    "    js = \"\"\"\n",
    "    () => {\n",
    "        const urls = new Set();\n",
    "        const addUrl = (u) => {\n",
    "            if (u && typeof u === 'string') {\n",
    "                urls.add(u);\n",
    "            }\n",
    "        };\n",
    "\n",
    "        document.querySelectorAll(\"a[href]\").forEach(el => addUrl(el.href));\n",
    "        document.querySelectorAll(\"img[src]\").forEach(el => addUrl(el.src));\n",
    "        document.querySelectorAll(\"iframe[src], embed[src]\").forEach(el => addUrl(el.src));\n",
    "        document.querySelectorAll(\"object[data]\").forEach(el => addUrl(el.data));\n",
    "\n",
    "        return Array.from(urls);\n",
    "    }\n",
    "    \"\"\"\n",
    "    raw = await safe_evaluate(page, js, default=[])\n",
    "    abs_urls = set()\n",
    "    for u in raw:\n",
    "        try:\n",
    "            full = urljoin(page.url, u)\n",
    "        except Exception:\n",
    "            full = u\n",
    "        if is_interesting_url(full, \"\"):\n",
    "            abs_urls.add(full)\n",
    "    return abs_urls\n",
    "\n",
    "# ------------------------- POPUP HANDLING -------------------------\n",
    "async def close_popups(page):\n",
    "    X_BUTTON_SELECTORS = [\n",
    "        \"button[aria-label*='close']\",\n",
    "        \"button[aria-label*='dismiss']\",\n",
    "        \"button:has-text('√ó')\",\n",
    "        \"button:has-text('‚úï')\",\n",
    "        \"div[role='button']:has-text('√ó')\",\n",
    "        \"[class*='close']\",\n",
    "        \"[id*='close']\",\n",
    "        \".close-btn\",\n",
    "        \".modal-close\",\n",
    "        \"[data-bs-dismiss='modal']\",\n",
    "    ]\n",
    "    CLOSE_TEXTS = [\n",
    "        \"close\", \"dismiss\", \"no thanks\", \"not now\",\n",
    "        \"skip\", \"cancel\", \"maybe later\",\n",
    "    ]\n",
    "    CLOSE_SELECTORS = [\n",
    "        \"button:has-text('Close')\",\n",
    "        \"button:has-text('CLOSE')\",\n",
    "        \"button:has-text('Dismiss')\",\n",
    "        \"[role='button']:has-text('Close')\",\n",
    "        \"[role='button']:has-text('Dismiss')\",\n",
    "    ]\n",
    "    ACCEPT_TEXTS = [\n",
    "        \"accept\", \"agree\", \"i agree\", \"accept all\",\n",
    "        \"got it\", \"continue\", \"ok\", \"okay\", \"allow\",\n",
    "    ]\n",
    "    ACCEPT_SELECTORS = [\n",
    "        \"button:has-text('Accept')\",\n",
    "        \"button:has-text('AGREE')\",\n",
    "        \"button:has-text('OK')\",\n",
    "        \"button:has-text('Got it')\",\n",
    "        \"[id*='cookie'] button\",\n",
    "        \"[class*='cookie'] button\",\n",
    "    ]\n",
    "\n",
    "    for _ in range(4):\n",
    "        clicked_something = False\n",
    "        for sel in X_BUTTON_SELECTORS:\n",
    "            locator = page.locator(sel)\n",
    "            if await locator.count() > 0:\n",
    "                count = await locator.count()\n",
    "                for i in range(count):\n",
    "                    try:\n",
    "                        elem = locator.nth(i)\n",
    "                        if await elem.is_visible() and await elem.is_enabled():\n",
    "                            await elem.click(timeout=1500)\n",
    "                            clicked_something = True\n",
    "                            await page.wait_for_timeout(500)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        if clicked_something:\n",
    "            continue\n",
    "\n",
    "        for sel in CLOSE_SELECTORS:\n",
    "            locator = page.locator(sel)\n",
    "            if await locator.count() > 0:\n",
    "                count = await locator.count()\n",
    "                for i in range(count):\n",
    "                    try:\n",
    "                        elem = locator.nth(i)\n",
    "                        if await elem.is_visible() and await elem.is_enabled():\n",
    "                            await elem.click(timeout=1500)\n",
    "                \n",
    "                            clicked_something = True\n",
    "                            await page.wait_for_timeout(500)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "        for txt in CLOSE_TEXTS:\n",
    "            locator = page.get_by_text(txt, exact=False)\n",
    "            if await locator.count() > 0:\n",
    "\n",
    "                count = await locator.count()\n",
    "                for i in range(count):\n",
    "                    try:\n",
    "                        elem = locator.nth(i)\n",
    "                        if await elem.is_visible() and await elem.is_enabled():\n",
    "                            await elem.click(timeout=1500)\n",
    "                        \n",
    "                            clicked_something = True\n",
    "                            await page.wait_for_timeout(500)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "        if clicked_something:\n",
    "            continue\n",
    "\n",
    "        for sel in ACCEPT_SELECTORS:\n",
    "            locator = page.locator(sel)\n",
    "            if await locator.count() > 0:\n",
    "                count = await locator.count()\n",
    "                for i in range(count):\n",
    "                    try:\n",
    "                        elem = locator.nth(i)\n",
    "                        if await elem.is_visible() and await elem.is_enabled():\n",
    "                            await elem.click(timeout=1500)\n",
    "                        \n",
    "                            clicked_something = True\n",
    "                            await page.wait_for_timeout(500)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "        for txt in ACCEPT_TEXTS:\n",
    "            locator = page.get_by_text(txt, exact=False)\n",
    "            if await locator.count() > 0:\n",
    "                count = await locator.count()\n",
    "                for i in range(count):\n",
    "                    try:\n",
    "                        elem = locator.nth(i)\n",
    "                        if await elem.is_visible() and await elem.is_enabled():\n",
    "                            await elem.click(timeout=1500)\n",
    "                    \n",
    "                            clicked_something = True\n",
    "                            await page.wait_for_timeout(500)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "        if not clicked_something:\n",
    "            break\n",
    "\n",
    "# ------------------------- OPPORTUNISTIC POPUP GUARD -------------------------\n",
    "async def opportunistic_close_popups(page):\n",
    "    \"\"\"\n",
    "    Lightweight, repeatable popup closer.\n",
    "    Safe to call many times.\n",
    "    Does NOT block execution.\n",
    "    \"\"\"\n",
    "\n",
    "    selectors = [\n",
    "        \"button[aria-label*='close' i]\",\n",
    "        \"button[aria-label*='dismiss' i]\",\n",
    "        \"[data-bs-dismiss='modal']\",\n",
    "        \".modal-close\",\n",
    "        \".close-btn\",\n",
    "        \"[class*='close']\",\n",
    "\n",
    "        # Cookie / consent\n",
    "        \"button:has-text('Accept')\",\n",
    "        \"button:has-text('AGREE')\",\n",
    "        \"button:has-text('OK')\",\n",
    "        \"button:has-text('Got it')\",\n",
    "        \"button:has-text('Allow')\",\n",
    "\n",
    "        # Generic dialog buttons\n",
    "        \"[role='dialog'] button\",\n",
    "    ]\n",
    "\n",
    "    for sel in selectors:\n",
    "        try:\n",
    "            loc = page.locator(sel)\n",
    "            if await loc.count() > 0:\n",
    "                for i in range(await loc.count()):\n",
    "                    btn = loc.nth(i)\n",
    "                    if await btn.is_visible():\n",
    "                        await btn.click(timeout=500)\n",
    "                        await page.wait_for_timeout(150)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "# ========================= HEADER / NAV DETECTORS =========================\n",
    "IS_GLOBAL_TOP_NAV_JS = r\"\"\"\n",
    "(el) => {\n",
    "    try {\n",
    "        // Semantic fast-path\n",
    "        if (el.closest('header, nav')) return true;\n",
    "\n",
    "        const style = getComputedStyle(el);\n",
    "        const pos = style.position;\n",
    "\n",
    "        if (pos !== 'fixed' && pos !== 'sticky') return false;\n",
    "\n",
    "        const r1 = el.getBoundingClientRect();\n",
    "        const vw = window.innerWidth;\n",
    "\n",
    "        // Must be near top and wide\n",
    "        if (r1.top > 80) return false;\n",
    "        if (r1.width < vw * 0.6 || r1.height < 40) return false;\n",
    "\n",
    "        // Scroll invariance test\n",
    "        window.scrollBy(0, 200);\n",
    "        const r2 = el.getBoundingClientRect();\n",
    "        window.scrollBy(0, -200);\n",
    "\n",
    "        return Math.abs(r1.top - r2.top) < 2;\n",
    "    } catch {\n",
    "        return false;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "IS_IN_HEADER_OR_FOOTER_JS = r\"\"\"\n",
    "(el) => {\n",
    "    try { return !!el.closest('header, footer'); }\n",
    "    catch(e){ return false; }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "IS_STICKY_OR_FIXED_NAV_JS = r\"\"\"\n",
    "(el) => {\n",
    "    try {\n",
    "        const s = getComputedStyle(el);\n",
    "        if (!s || (s.position !== 'fixed' && s.position !== 'sticky')) return false;\n",
    "\n",
    "        const r1 = el.getBoundingClientRect();\n",
    "        const vh = window.innerHeight;\n",
    "\n",
    "        const anchored = r1.top <= 5 || r1.bottom >= vh - 5;\n",
    "        if (!anchored) return false;\n",
    "\n",
    "        if (r1.height < 40 || r1.width < window.innerWidth * 0.5) return false;\n",
    "\n",
    "        window.scrollBy(0,200);\n",
    "        const r2 = el.getBoundingClientRect();\n",
    "        window.scrollBy(0,-200);\n",
    "\n",
    "        return Math.abs(r1.top - r2.top) < 2;\n",
    "    } catch(e){\n",
    "        return false;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "async def is_in_header_or_footer(elem):\n",
    "    return await safe_elem_evaluate(elem, IS_IN_HEADER_OR_FOOTER_JS, default=False)\n",
    "\n",
    "async def is_sticky_or_fixed_nav(elem):\n",
    "    return await safe_elem_evaluate(elem, IS_STICKY_OR_FIXED_NAV_JS, default=False)\n",
    "\n",
    "async def is_global_top_nav(elem):\n",
    "    try:\n",
    "        return await safe_elem_evaluate(elem, IS_GLOBAL_TOP_NAV_JS, default=False)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# ========================= PLAYWRIGHT HARDENING LAYER =========================\n",
    "\n",
    "\n",
    "\n",
    "async def safe_wait(page, ms=300):\n",
    "    try:\n",
    "        if page.is_closed():\n",
    "            return\n",
    "        await page.wait_for_timeout(ms)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "async def safe_load_wait(page, state=\"domcontentloaded\", timeout=10000):\n",
    "    try:\n",
    "        if page.is_closed():\n",
    "            return False\n",
    "        await page.wait_for_load_state(state, timeout=timeout)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "async def safe_evaluate(page, script, *, timeout_ms=10000, default=None):\n",
    "    \"\"\"\n",
    "    GUARDED page.evaluate\n",
    "    - Handles navigation\n",
    "    - Handles reload\n",
    "    - Handles page close\n",
    "    - Never throws\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if page.is_closed():\n",
    "            return default\n",
    "\n",
    "        await page.wait_for_load_state(\"domcontentloaded\", timeout=timeout_ms)\n",
    "\n",
    "        return await page.evaluate(script)\n",
    "\n",
    "    except (PlaywrightError, TimeoutError):\n",
    "        return default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "async def safe_elem_evaluate(elem, script, default=None):\n",
    "    \"\"\"\n",
    "    GUARDED element.evaluate\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return await elem.evaluate(script)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "async def safe_click(elem, *, timeout=1500):\n",
    "    \"\"\"\n",
    "    GUARDED click\n",
    "    - Handles detached elements\n",
    "    - Handles navigation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not await elem.is_visible():\n",
    "            return False\n",
    "        if not await elem.is_enabled():\n",
    "            return False\n",
    "\n",
    "        await elem.scroll_into_view_if_needed(timeout=timeout)\n",
    "        await elem.click(timeout=timeout)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "async def safe_select_option(select_elem, *, index=None, value=None, timeout=1000):\n",
    "    \"\"\"\n",
    "    GUARDED select_option\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if index is not None:\n",
    "            await select_elem.select_option(index=index, timeout=timeout)\n",
    "        elif value is not None:\n",
    "            await select_elem.select_option(value=value, timeout=timeout)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "async def safe_inner_text(elem, default=\"\"):\n",
    "    try:\n",
    "        return (await elem.inner_text()).strip()\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "async def safe_get_attr(elem, attr):\n",
    "    try:\n",
    "        return await elem.get_attribute(attr)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# ------------------------- AUTO SCROLL -------------------------\n",
    "async def auto_scroll(page, rounds=3, delay_ms=1000): #auto-scroll with delay\n",
    "    \"\"\"\n",
    "    Enhanced scroll to trigger lazy-loaded / intersection-observer content.\n",
    "    \"\"\"\n",
    "    last_height = 0\n",
    "\n",
    "    async with page_task(page) as ok:\n",
    "        if not ok:\n",
    "            return\n",
    "\n",
    "        for r in range(rounds):\n",
    "            if page._closing or page.is_closed():\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                height = await safe_evaluate(\n",
    "                    page,\n",
    "                    \"() => document.body.scrollHeight\",\n",
    "                    default=0\n",
    "                )\n",
    "                if height == last_height:\n",
    "                    break\n",
    "                last_height = height\n",
    "\n",
    "                await safe_evaluate(\n",
    "                    page,\n",
    "                    \"() => window.scrollTo(0, document.body.scrollHeight)\"\n",
    "                )\n",
    "                await page.wait_for_timeout(delay_ms)\n",
    "\n",
    "                # slight scroll up to re-trigger observers\n",
    "                await safe_evaluate(\n",
    "                    page,\n",
    "                    \"() => window.scrollBy(0, -300)\"\n",
    "                )\n",
    "                await page.wait_for_timeout(250)\n",
    "\n",
    "                print(f\"[DEBUG] Scroll round {r+1}/{rounds} completed\")\n",
    "\n",
    "            except Exception:\n",
    "                break\n",
    "\n",
    "\n",
    "# ------------------------- CLICK-BASED DISCOVERY (kept but unused) -------------------------\n",
    "'''\n",
    "async def click_and_capture_urls(page, elem, timeout_ms=5000):\n",
    "    context = page.context\n",
    "    original_url = page.url\n",
    "    before_dom_urls = await collect_dom_urls(page)\n",
    "    new_urls = set()\n",
    "\n",
    "    try:\n",
    "        async with context.expect_page(timeout=timeout_ms) as pop_info:\n",
    "            await elem.click()\n",
    "        popup = await pop_info.value\n",
    "\n",
    "        try:\n",
    "            await popup.wait_for_load_state(\"load\", timeout=timeout_ms)\n",
    "        except TimeoutError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            popup_url = popup.url\n",
    "        except Exception:\n",
    "            popup_url = \"\"\n",
    "\n",
    "        if is_interesting_url(popup_url, \"\") and url_matches_keywords(popup_url, \"\"):\n",
    "            new_urls.add(popup_url)\n",
    "\n",
    "        popup_dom_urls = await collect_dom_urls(popup)\n",
    "        for u in popup_dom_urls:\n",
    "            if url_matches_keywords(u, \"\"):\n",
    "                new_urls.add(u)\n",
    "\n",
    "        try:\n",
    "            await popup.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "        return new_urls\n",
    "    except TimeoutError:\n",
    "        pass\n",
    "    except Exception:\n",
    "        return new_urls\n",
    "\n",
    "    try:\n",
    "        await page.wait_for_timeout(2000)\n",
    "        new_url = page.url\n",
    "\n",
    "        if new_url != original_url:\n",
    "            if is_interesting_url(new_url, \"\") and url_matches_keywords(new_url, \"\"):\n",
    "                new_urls.add(new_url)\n",
    "\n",
    "            dom_urls = await collect_dom_urls(page)\n",
    "            for u in dom_urls:\n",
    "                if url_matches_keywords(u, \"\"):\n",
    "                    new_urls.add(u)\n",
    "\n",
    "            try:\n",
    "                if page.can_go_back():\n",
    "                    await page.go_back()\n",
    "                    await page.wait_for_load_state(\"load\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            after_dom_urls = await collect_dom_urls(page)\n",
    "            added = after_dom_urls - before_dom_urls\n",
    "\n",
    "            for u in added:\n",
    "                if url_matches_keywords(u, \"\"):\n",
    "                    new_urls.add(u)\n",
    "\n",
    "    except Exception:\n",
    "        return new_urls\n",
    "\n",
    "    return new_urls\n",
    "'''\n",
    "\n",
    "'''\n",
    "def is_any_category_related(text: str, url: str) -> bool:\n",
    "    combined = f\"{text} {url}\".lower()\n",
    "    for kws in CATEGORY_KEYWORDS.values():\n",
    "        for kw in kws:\n",
    "            kw = kw.strip().lower()\n",
    "            if not kw:\n",
    "                continue\n",
    "            if re.search(rf\"\\b{re.escape(kw)}\\b\", combined):\n",
    "                return True\n",
    "    return False\n",
    "'''\n",
    "\n",
    "\n",
    "# ------------------------- VISIT & COLLECT (HEADING-BASED EXTRACTION IMPLEMENTED) -------------------------\n",
    "from urllib.parse import unquote\n",
    "\n",
    "def merge_text(base: str, *extras: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely append contextual text without overwriting.\n",
    "    Preserves base text ALWAYS.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    if base:\n",
    "        parts.append(base.strip())\n",
    "\n",
    "    for e in extras:\n",
    "        if e and e.strip():\n",
    "            parts.append(e.strip())\n",
    "\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def upsert_artifact(page, norm, raw_url, new_text):\n",
    "    \"\"\"\n",
    "    Append text to an existing artifact if already seen.\n",
    "    Never overwrites richer context.\n",
    "    \"\"\"\n",
    "    if not new_text:\n",
    "        new_text = \"\"\n",
    "\n",
    "    old = page._seen_artifacts.get(norm)\n",
    "\n",
    "    if old:\n",
    "        old_text = old.get(\"text\", \"\")\n",
    "        merged = merge_text(old_text, new_text)\n",
    "\n",
    "        if should_accept_context(old_text, merged):\n",
    "            old[\"text\"] = merged\n",
    "    else:\n",
    "        page._seen_artifacts[norm] = {\n",
    "            \"raw\": raw_url,\n",
    "            \"text\": new_text\n",
    "        }\n",
    "\n",
    "\n",
    "def is_pdf(url: str) -> bool:\n",
    "    return url.lower().endswith(\".pdf\")\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "DOCUMENT_EXTENSIONS = {\n",
    "    \"pdf\": [\".pdf\"],\n",
    "    \"excel\": [\".xls\", \".xlsx\", \".csv\", \".ods\",\".tsv\", \".xlt\", \".xltx\"],\n",
    "    \"word\": [\".doc\", \".docx\", \".rtf\",\".odt\",\".tex\",\".dot\",\".dotx\"],\n",
    "    \"ppt\": [\".ppt\", \".pptx\", \".pps\", \".ppsx\"],\n",
    "    \"archive\": [\".zip\", \".rar\", \".7z\", \".tar\", \".gz\", \".bz2\"],\n",
    "    \"text\": [\".txt\", \".log\", \".dat\"],\n",
    "    \"images\": [\".jpg\", \".jpeg\", \".png\", \".tiff\", \".bmp\"]\n",
    "}\n",
    "\n",
    "def classify_document_url(url: str) -> str | None:\n",
    "    if not url:\n",
    "        return None\n",
    "\n",
    "    u = url.lower().split(\"?\", 1)[0]\n",
    "\n",
    "    # üîπ Google Drive (highest priority)\n",
    "    if \"drive.google.com\" in u:\n",
    "        return \"google_drive\"\n",
    "\n",
    "    # üîπ Normal document extensions\n",
    "    for category, exts in DOCUMENT_EXTENSIONS.items():\n",
    "        if any(u.endswith(ext) for ext in exts):\n",
    "            return category\n",
    "\n",
    "    '''\n",
    "    # üîπ Heuristic fallback (download.php, file=, action=)\n",
    "    if re.search(r\"(download|file=|action=)\", u):\n",
    "        return \"other_document\"\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "CATEGORY_PRIORITY = [\n",
    "    \"criteria_1\",\"criteria_2\",\"criteria_3\",\"criteria_4\",\n",
    "    \"criteria_5\",\"criteria_6\",\"criteria_7\",\n",
    "    \"mandatory_disclosure\",\n",
    "    \"aicte\",\n",
    "    \"naac\",\n",
    "    \"nba\",\n",
    "    \"nirf\",\n",
    "    \"iqac\",\n",
    "    \"aqar\",\n",
    "    \"ariia\",\n",
    "    \"accreditation\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def pick_category(text: str, href: str, page_category: str | None = None) -> str | None:\n",
    "    combined = f\"{text} {href}\".lower()\n",
    "\n",
    "    keywords = CATEGORY_KEYWORDS.copy()\n",
    "\n",
    "    if page_category == \"naac\":\n",
    "        keywords[\"naac\"] = keywords[\"naac\"] + [\n",
    "            \"iqac\",\"iiqa\",\"ssr\",\"dvv\",\"qif\",\n",
    "            \"quality indicator framework\",\n",
    "            \"criterion\",\"criteria\",\"metric\",\"cycle\",\"crit\"\n",
    "        ]\n",
    "\n",
    "    for cat in CATEGORY_PRIORITY:\n",
    "        for kw in keywords.get(cat, []):\n",
    "            if not kw:\n",
    "                continue\n",
    "            pattern = rf\"\\b{re.escape(kw)}\\b\"\n",
    "            if re.search(pattern, combined):\n",
    "                return cat\n",
    "    return None\n",
    "\n",
    "def is_document_file(url: str) -> bool:\n",
    "    if not url:\n",
    "        return False\n",
    "\n",
    "    clean = url.lower()\n",
    "\n",
    "    if \"drive.google.com\" in clean:\n",
    "        return True\n",
    "\n",
    "    clean = clean.split(\"?\", 1)[0]\n",
    "\n",
    "    for exts in DOCUMENT_EXTENSIONS.values():\n",
    "        if any(clean.endswith(ext) for ext in exts):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def classify_url(raw_url: str, text: str, page_category: str | None):\n",
    "    \"\"\"\n",
    "    PURE classification.\n",
    "    No dedupe. No global state. No storage.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2Ô∏è‚É£ Category-related non-PDF\n",
    "    cat = pick_category(text, raw_url, page_category)\n",
    "    if cat:\n",
    "        return \"nonpdf_category_related\", cat\n",
    "\n",
    "    # 3Ô∏è‚É£ Everything else\n",
    "    return \"nonpdf_other\", \"accreditation\"\n",
    "\n",
    "YEAR_CUTOFF = 2020\n",
    "\n",
    "YEAR_REGEX = re.compile(r\"\\b(20\\d{2})\\b\")\n",
    "\n",
    "def is_old_year_content(text: str, url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if text or URL contains a year < YEAR_CUTOFF.\n",
    "    \"\"\"\n",
    "    combined = f\"{text} {url}\"\n",
    "    years = YEAR_REGEX.findall(combined)\n",
    "\n",
    "    if not years:\n",
    "        return False  # no year ‚Üí keep\n",
    "\n",
    "    try:\n",
    "        years_int = [int(y) for y in years]\n",
    "    except Exception:\n",
    "        return False  # malformed ‚Üí keep safe\n",
    "\n",
    "    return False  # max(years_int) < YEAR_CUTOFF\n",
    "\n",
    "\n",
    "def accept_and_store(\n",
    "    *,\n",
    "    raw_url: str,\n",
    "    enriched_text: str,\n",
    "    page_category: str | None,\n",
    "    category_links: dict,\n",
    "    page,\n",
    "):\n",
    "    # üîí HARD STOP: discard old-year content entirely\n",
    "    if is_old_year_content(enriched_text, raw_url):\n",
    "        return\n",
    "\n",
    "    # =====================================================\n",
    "    # 1Ô∏è‚É£ DOCUMENT CLASSIFICATION (single source of truth)\n",
    "    # =====================================================\n",
    "    doc_type = classify_document_url(raw_url)\n",
    "\n",
    "    if doc_type:\n",
    "        bucket = doc_type\n",
    "        inferred_cat = page_category or \"accreditation\"\n",
    "    else:\n",
    "        # =================================================\n",
    "        # 2Ô∏è‚É£ NON-DOCUMENT CLASSIFICATION\n",
    "        # =================================================\n",
    "        bucket, inferred_cat = classify_url(\n",
    "            raw_url, enriched_text, page_category\n",
    "        )\n",
    "\n",
    "    # =====================================================\n",
    "    # 3Ô∏è‚É£ Decide column (category)\n",
    "    # =====================================================\n",
    "    criteria_col = infer_criteria_column(enriched_text, raw_url)\n",
    "    if criteria_col:\n",
    "        store_cat = criteria_col\n",
    "    elif page_category:\n",
    "        store_cat = page_category\n",
    "    else:\n",
    "        store_cat = inferred_cat or \"accreditation\"\n",
    "\n",
    "    # =====================================================\n",
    "    # 4Ô∏è‚É£ Typed dedupe key\n",
    "    # =====================================================\n",
    "    dedupe_key = make_dedupe_key(raw_url, bucket)\n",
    "\n",
    "    # Page-level dedupe\n",
    "    if dedupe_key in page._page_seen_urls:\n",
    "        return\n",
    "    page._page_seen_urls.add(dedupe_key)\n",
    "\n",
    "    # Global dedupe\n",
    "    if dedupe_key in GLOBAL_SEEN_ARTIFACTS:\n",
    "        return\n",
    "    GLOBAL_SEEN_ARTIFACTS.add(dedupe_key)\n",
    "\n",
    "    # =====================================================\n",
    "    # 5Ô∏è‚É£ STORE (NO re-classification later)\n",
    "    # =====================================================\n",
    "    category_links[store_cat].append(\n",
    "        (bucket, f\"{raw_url} || {enriched_text}\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def assign_category(\n",
    "    category_links: dict,\n",
    "    *,\n",
    "    url: str,\n",
    "    text: str,\n",
    "    depth: int,\n",
    "    page_category: str | None,\n",
    "):\n",
    "    norm = normalize_url(url, \"\")\n",
    "\n",
    "    # üîí HARD STOP: URL already seen anywhere\n",
    "    if norm in GLOBAL_URL_OWNERS:\n",
    "        return\n",
    "\n",
    "    # 1Ô∏è‚É£ Criteria override\n",
    "    criteria_cat = detect_criteria_category(text, url)\n",
    "    if criteria_cat:\n",
    "        if claim_url_once(url, text, criteria_cat, depth):\n",
    "            category_links[criteria_cat].append(f\"{url} || {text}\")\n",
    "        return\n",
    "\n",
    "    # 2Ô∏è‚É£ PDF rule\n",
    "    if is_pdf(url):\n",
    "        cat = page_category or \"accreditation\"\n",
    "        if claim_url_once(url, text, cat, depth):\n",
    "            category_links[cat].append(f\"{url} || {text}\")\n",
    "        return\n",
    "\n",
    "    # 3Ô∏è‚É£ Inherit page category\n",
    "    if page_category:\n",
    "        if claim_url_once(url, text, page_category, depth):\n",
    "            category_links[page_category].append(f\"{url} || {text}\")\n",
    "        return\n",
    "\n",
    "    # 4Ô∏è‚É£ Deterministic category pick\n",
    "    cat = pick_category(text, url,page_category)\n",
    "    if cat:\n",
    "        if claim_url_once(url, text, cat, depth):\n",
    "            category_links[cat].append(f\"{url} || {text}\")\n",
    "        return\n",
    "'''\n",
    "\n",
    "async def wait_for_new_pdf(page, before_set, timeout_ms=5000, poll_ms=200):\n",
    "    waited = 0\n",
    "    while waited < timeout_ms:\n",
    "        await page.wait_for_timeout(poll_ms)\n",
    "        if page._local_seen_pdf - before_set:\n",
    "            return True\n",
    "        waited += poll_ms\n",
    "    return False\n",
    "\n",
    "'''\n",
    "async def is_interactive_page(page) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristically determine whether a page requires interaction\n",
    "    to reveal content.\n",
    "    \"\"\"\n",
    "    js = \"\"\"\n",
    "    () => {\n",
    "        return Boolean(\n",
    "            document.querySelector('[role=\"tab\"]') ||\n",
    "            document.querySelector('[role=\"tab\"]') ||\n",
    "            document.querySelector('details > summary') ||\n",
    "            document.querySelector('select') ||\n",
    "            document.querySelector('select option') ||\n",
    "            document.querySelector('[aria-controls]') \n",
    "        );\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return await safe_evaluate(page, js, default=False)\n",
    "    except Exception:\n",
    "        return False\n",
    "'''\n",
    "async def interact_and_capture_pdfs(page, elem,*, force_click= False):\n",
    "    \"\"\"\n",
    "    Click an element ONLY if:\n",
    "    - it has relevant keywords OR\n",
    "    - it is a <button> (form submit / viewer triggers)\n",
    "    \"\"\"\n",
    "\n",
    "    allow_click = False\n",
    "    text = \"\"\n",
    "\n",
    "    try:\n",
    "        text = (await elem.inner_text()).lower()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 1Ô∏è‚É£ Keyword-based allow (existing logic)\n",
    "    if force_click:\n",
    "        allow_click = True\n",
    "    else:\n",
    "        if any(k in text for k in CLICK_KEYWORDS):\n",
    "            allow_click = True\n",
    "\n",
    "\n",
    "    # 2Ô∏è‚É£ NEW: Allow generic <button> clicks (form submits)\n",
    "    try:\n",
    "        tag = await elem.evaluate(\"el => el.tagName\")\n",
    "        if tag == \"BUTTON\":\n",
    "            allow_click = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if not allow_click:\n",
    "        return set()\n",
    "\n",
    "    before = set(page._local_seen_pdf)\n",
    "\n",
    "    try:\n",
    "        await opportunistic_close_popups(page)   # ‚úÖ ADD\n",
    "        if not await elem.is_visible():\n",
    "            return set()\n",
    "        await elem.scroll_into_view_if_needed(timeout=1500)\n",
    "        await opportunistic_close_popups(page)   # ‚úÖ ADD\n",
    "        await safe_click(elem, timeout=1500)\n",
    "        await safe_load_wait(page)\n",
    "    except Exception:\n",
    "        return set()\n",
    "\n",
    "\n",
    "    await wait_for_new_pdf(page, before_set=before, timeout_ms=6000)\n",
    "    return page._local_seen_pdf - before\n",
    "\n",
    "'''\n",
    "def get_resource_state(page):\n",
    "    \"\"\"\n",
    "    The ONLY state that determines convergence.\n",
    "    \"\"\"\n",
    "    return frozenset(page._local_seen_pdf)\n",
    "'''\n",
    "def get_page_resource_state(page):\n",
    "    \"\"\"\n",
    "    Canonical convergence state:\n",
    "    ANY new URL (PDF or non-PDF, DOM or network) counts as progress.\n",
    "    \"\"\"\n",
    "    return frozenset(page._seen_artifacts.keys())\n",
    "\n",
    "async def is_cyclic_ui_element(elem):\n",
    "    \"\"\"\n",
    "    Detect infinite / cyclic UI components (carousels, sliders, rotators)\n",
    "    and permanently blacklist them.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return await safe_elem_evaluate(\n",
    "            elem,\n",
    "            \"\"\"\n",
    "            el => {\n",
    "                function isCarouselContainer(n) {\n",
    "                    if (!n || n === document.body) return false;\n",
    "\n",
    "                    const cls = (n.className || '').toLowerCase();\n",
    "                    const role = (n.getAttribute && n.getAttribute('role')) || '';\n",
    "                    const aria = (n.getAttribute && n.getAttribute('aria-roledescription')) || '';\n",
    "\n",
    "                    const isCarousel =\n",
    "                        aria === 'carousel' ||\n",
    "                        cls.includes('carousel') ||\n",
    "                        cls.includes('slider') ||\n",
    "                        cls.includes('owl-') ||\n",
    "                        cls.includes('swiper') ||\n",
    "                        cls.includes('slick');\n",
    "\n",
    "                    if (isCarousel) {\n",
    "                        // üîí POISON PILL: permanently mark subtree\n",
    "                        n.dataset.__crawler_skip = \"1\";\n",
    "                        return true;\n",
    "                    }\n",
    "\n",
    "                    const style = getComputedStyle(n);\n",
    "\n",
    "                    if (style.transform && style.transform !== 'none') {\n",
    "                        n.dataset.__crawler_skip = \"1\";\n",
    "                        return true;\n",
    "                    }\n",
    "\n",
    "                    if (style.overflow === 'hidden' && n.children.length > 1) {\n",
    "                        n.dataset.__crawler_skip = \"1\";\n",
    "                        return true;\n",
    "                    }\n",
    "\n",
    "                    if (n.querySelectorAll('[class*=\"cloned\"]').length > 0) {\n",
    "                        n.dataset.__crawler_skip = \"1\";\n",
    "                        return true;\n",
    "                    }\n",
    "\n",
    "                    if (n.querySelectorAll('.active').length > 1) {\n",
    "                        n.dataset.__crawler_skip = \"1\";\n",
    "                        return true;\n",
    "                    }\n",
    "\n",
    "                    return isCarouselContainer(n.parentElement);\n",
    "                }\n",
    "\n",
    "                return isCarouselContainer(el);\n",
    "            }\n",
    "        \"\"\",\n",
    "        default= False\n",
    "        )\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "'''\n",
    "async def is_cyclic_ui_element(elem):\n",
    "    \"\"\"\n",
    "    Detect infinite / cyclic UI components (carousels, sliders, rotators).\n",
    "    Framework-agnostic.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return await elem.evaluate(\"\"\"\n",
    "            el => {\n",
    "                function isCarouselContainer(n) {\n",
    "                    if (!n || n === document.body) return false;\n",
    "\n",
    "                    const cls = (n.className || '').toLowerCase();\n",
    "                    const role = (n.getAttribute && n.getAttribute('role')) || '';\n",
    "                    const aria = (n.getAttribute && n.getAttribute('aria-roledescription')) || '';\n",
    "\n",
    "                    // Known semantic signals\n",
    "                    if (aria === 'carousel') return true;\n",
    "                    if (role === 'tablist' && n.querySelector('[aria-selected]')) return true;\n",
    "\n",
    "                    // Common class indicators\n",
    "                    if (\n",
    "                        cls.includes('carousel') ||\n",
    "                        cls.includes('slider') ||\n",
    "                        cls.includes('owl-') ||\n",
    "                        cls.includes('swiper') ||\n",
    "                        cls.includes('slick')\n",
    "                    ) return true;\n",
    "\n",
    "                    const style = getComputedStyle(n);\n",
    "\n",
    "                    // Sliding transforms\n",
    "                    if (style.transform && style.transform !== 'none')\n",
    "                        return true;\n",
    "\n",
    "                    // Masked viewport (slides move inside)\n",
    "                    if (style.overflow === 'hidden' && n.children.length > 1)\n",
    "                        return true;\n",
    "\n",
    "                    // Cloned / rotating items\n",
    "                    if (n.querySelectorAll('[class*=\"cloned\"]').length > 0)\n",
    "                        return true;\n",
    "\n",
    "                    // Multiple active elements = rotation\n",
    "                    if (n.querySelectorAll('.active').length > 1)\n",
    "                        return true;\n",
    "\n",
    "                    return isCarouselContainer(n.parentElement);\n",
    "                }\n",
    "\n",
    "                return isCarouselContainer(el);\n",
    "            }\n",
    "        \"\"\")\n",
    "    except Exception:\n",
    "        return False\n",
    "'''\n",
    "\n",
    "async def is_poisoned(elem):\n",
    "    try:\n",
    "        return await safe_elem_evaluate(\n",
    "            elem,\n",
    "            \"el => el.closest('[data-__crawler-skip=\\\"1\\\"]') !== null\",\n",
    "            default=False\n",
    "        )\n",
    "\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "async def handle_tabs(page,depth):\n",
    "\n",
    "    tabs = page.locator('[role=\"tab\"]')\n",
    "    count = await tabs.count()\n",
    "    if count == 0:\n",
    "        return set(), False\n",
    "\n",
    "    found_pdfs = set()\n",
    "    did_progress = False\n",
    "\n",
    "    for i in range(count):\n",
    "        await opportunistic_close_popups(page)   # ‚úÖ ADD\n",
    "        tab = tabs.nth(i)\n",
    "        if depth >= 1:\n",
    "            if await is_global_top_nav(tab):\n",
    "                continue\n",
    "        '''\n",
    "        if depth >= 1:\n",
    "            if await is_in_header_or_footer(tab): \n",
    "                continue\n",
    "            if await is_sticky_or_fixed_nav(tab):\n",
    "                continue\n",
    "        '''\n",
    "        #if await is_cyclic_ui_element(tab):\n",
    "         #   continue \n",
    "\n",
    "        try:\n",
    "            if await tab.is_disabled():\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if await is_poisoned(tab):\n",
    "            continue\n",
    "\n",
    "        fingerprint = await get_element_fingerprint(tab)\n",
    "        if fingerprint in page._clicked_elements:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            selected = await tab.get_attribute(\"aria-selected\")\n",
    "            if selected == \"true\":\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        before_pdfs = len(page._local_seen_pdf)\n",
    "        before_dom = await get_structural_dom_signature(page)\n",
    "\n",
    "        # üîπ capture tab text BEFORE clicking\n",
    "        tab_text = await get_element_context_text(tab)\n",
    "\n",
    "        # üîπ click and capture PDFs\n",
    "        pdfs = await interact_and_capture_pdfs(page, tab, force_click=True)\n",
    "\n",
    "        after_pdfs = len(page._local_seen_pdf)\n",
    "        after_dom = await get_structural_dom_signature(page)\n",
    "\n",
    "        # ‚úÖ ONLY NOW decide progress\n",
    "        if after_pdfs > before_pdfs or after_dom != before_dom:\n",
    "            did_progress = True\n",
    "\n",
    "        # ‚úÖ ALWAYS mark as clicked (even if useless)\n",
    "        page._clicked_elements.add(fingerprint)\n",
    "\n",
    "\n",
    "        # üîπ NEW: enrich PDF context with tab text\n",
    "        for pdf in pdfs:\n",
    "            norm = normalize_url(pdf, \"\")\n",
    "            upsert_artifact(page, norm, pdf, tab_text)\n",
    "\n",
    "        found_pdfs |= pdfs\n",
    "\n",
    "    return found_pdfs, did_progress\n",
    "\n",
    "\n",
    "\n",
    "async def handle_accordions(page,depth):\n",
    "    toggles = page.locator('[aria-expanded][role=\"button\"], details > summary')\n",
    "\n",
    "    found_pdfs = set()\n",
    "    did_progress = False\n",
    "\n",
    "    for i in range(await toggles.count()):\n",
    "        await opportunistic_close_popups(page)   # ‚úÖ ADD\n",
    "        el = toggles.nth(i)\n",
    "\n",
    "        if depth >= 1:\n",
    "            if await is_global_top_nav(el):\n",
    "                continue\n",
    "        '''\n",
    "        if depth >= 1:\n",
    "            if await is_in_header_or_footer(el): \n",
    "                continue\n",
    "            if await is_sticky_or_fixed_nav(el):\n",
    "                continue\n",
    "        '''\n",
    "        #if await is_cyclic_ui_element(el):\n",
    "         #   continue\n",
    "        # üö´ EXCLUDE SLIDERS / CAROUSELS EARLY\n",
    "        try:\n",
    "            cls = (await el.get_attribute(\"class\") or \"\").lower()\n",
    "            role = (await el.get_attribute(\"role\") or \"\").lower()\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # üîé Skip already-open accordions\n",
    "        try:\n",
    "            expanded = await el.get_attribute(\"aria-expanded\")\n",
    "            if expanded == \"true\":\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if await is_poisoned(el):\n",
    "            continue\n",
    "\n",
    "        fingerprint = await get_element_fingerprint(el)\n",
    "        if fingerprint in page._clicked_elements:\n",
    "            continue\n",
    "\n",
    "        # ‚úÖ REAL accordion discovered\n",
    "        before_pdfs = len(page._local_seen_pdf)\n",
    "        before_dom = await get_structural_dom_signature(page)\n",
    "\n",
    "        pdfs = await interact_and_capture_pdfs(page, el, force_click=True)\n",
    "        found_pdfs |= pdfs\n",
    "\n",
    "        after_pdfs = len(page._local_seen_pdf)\n",
    "        after_dom = await get_structural_dom_signature(page)\n",
    "\n",
    "        if after_pdfs > before_pdfs or after_dom != before_dom:\n",
    "            did_progress = True\n",
    "\n",
    "        # ‚úÖ ALWAYS mark as clicked\n",
    "        page._clicked_elements.add(fingerprint)\n",
    "        \n",
    "\n",
    "    return found_pdfs, did_progress\n",
    "\n",
    "\n",
    "\n",
    "async def handle_dropdowns(page,depth):\n",
    "    found_pdfs = set()\n",
    "    did_progress = False\n",
    "    selects = page.locator(\"select\")\n",
    "\n",
    "    for i in range(await selects.count()):\n",
    "        await opportunistic_close_popups(page)   # ‚úÖ ADD\n",
    "        sel = selects.nth(i)\n",
    "        \n",
    "        if depth >= 1:\n",
    "            if await is_global_top_nav(sel):\n",
    "                continue\n",
    "\n",
    "        ''''\n",
    "        if depth >= 1:\n",
    "            if await is_in_header_or_footer(sel): \n",
    "                continue\n",
    "            if await is_sticky_or_fixed_nav(sel):\n",
    "                continue\n",
    "        '''\n",
    "        #if await is_cyclic_ui_element(sel):\n",
    "        #    continue\n",
    "\n",
    "        if await is_poisoned(sel):\n",
    "            continue\n",
    "\n",
    "        fingerprint = await get_element_fingerprint(sel)\n",
    "        if fingerprint in page._clicked_elements:\n",
    "            continue\n",
    "\n",
    "        # ‚úÖ NEW INTERACTABLE FOUND ‚Üí PROGRESS\n",
    "        before_pdfs = len(page._local_seen_pdf)\n",
    "        before_dom = await get_structural_dom_signature(page)\n",
    "\n",
    "        options = sel.locator(\"option\")\n",
    "\n",
    "        for j in range(await options.count()):\n",
    "            try:\n",
    "                opt = options.nth(j)\n",
    "                if not await opt.is_enabled():\n",
    "                    continue\n",
    "\n",
    "                before = set(page._local_seen_pdf)\n",
    "\n",
    "                try:\n",
    "                    await sel.select_option(index=j, timeout=1000)\n",
    "                    await safe_load_wait(page)  \n",
    "                except PlaywrightError:\n",
    "                    break  # üîí page closed / element invalid ‚Üí stop dropdown safely\n",
    "\n",
    "                await wait_for_new_pdf(page, before_set=before, timeout_ms=3000)\n",
    "                found_pdfs |= (page._local_seen_pdf - before)\n",
    "\n",
    "            except Exception:\n",
    "                break\n",
    "\n",
    "\n",
    "        after_pdfs = len(page._local_seen_pdf)\n",
    "        after_dom = await get_structural_dom_signature(page)\n",
    "\n",
    "        if after_pdfs > before_pdfs or after_dom != before_dom:\n",
    "            did_progress = True\n",
    "\n",
    "        # ‚úÖ ALWAYS mark dropdown as clicked\n",
    "        page._clicked_elements.add(fingerprint)\n",
    "        \n",
    "    return found_pdfs, did_progress\n",
    "\n",
    "'''\n",
    "async def handle_sliders(page):\n",
    "    # Slider already tested once ‚Üí stop forever\n",
    "    if getattr(page, \"_slider_exhausted\", False):\n",
    "        return set(), False\n",
    "\n",
    "    candidates = page.locator(\n",
    "        '[aria-label*=\"next\"], [aria-label*=\"Next\"], button:has-text(\">\"), button:has-text(\"‚Üí\")'\n",
    "    )\n",
    "\n",
    "    if await candidates.count() == 0:\n",
    "        return set(), False\n",
    "\n",
    "    page._slider_exhausted = True  # üîí critical line\n",
    "\n",
    "    found_pdfs = set()\n",
    "\n",
    "    for i in range(min(await candidates.count(), 2)):\n",
    "        btn = candidates.nth(i)\n",
    "        try:\n",
    "            await btn.scroll_into_view_if_needed(timeout=1500)\n",
    "            pdfs = await interact_and_capture_pdfs(page, btn)\n",
    "            found_pdfs |= pdfs\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ‚ùå sliders never signal \"progress\"\n",
    "    return found_pdfs, False\n",
    "\n",
    "'''\n",
    "async def get_structural_dom_signature(page):\n",
    "    return await safe_evaluate(\n",
    "        page,\n",
    "        \"\"\"\n",
    "        () => {\n",
    "            const body = document.body;\n",
    "            if (!body) return 0;\n",
    "            return body.querySelectorAll(\n",
    "                'a[href], iframe, embed, object, details, summary, select, option'\n",
    "            ).length;\n",
    "        }\n",
    "        \"\"\",\n",
    "        default=0\n",
    "    )\n",
    "\n",
    "\n",
    "async def get_dom_text_signature(page):\n",
    "    try:\n",
    "        return await safe_evaluate(\n",
    "            page,\n",
    "            \"() => document.body ? document.body.innerText.length : 0\",\n",
    "            default=0\n",
    "        )\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "async def get_anchor_count(page):\n",
    "    try:\n",
    "        return await safe_evaluate(\n",
    "            page,\n",
    "            \"() => document.querySelectorAll('a[href]').length\",\n",
    "            default=0\n",
    "        )\n",
    "\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "async def get_iframe_count(page):\n",
    "    try:\n",
    "        return len(page.frames)\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def log_soft_error(college_name: str, url: str, reason: str):\n",
    "    try:\n",
    "        with open(ERROR_LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "            f.write(f\"TIMESTAMP : {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"COLLEGE   : {college_name}\\n\")\n",
    "            f.write(f\"URL       : {url}\\n\")\n",
    "            f.write(\"SOFT ERROR:\\n\")\n",
    "            f.write(reason + \"\\n\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "async def goto_with_retry(\n",
    "    page,\n",
    "    url: str,\n",
    "    *,\n",
    "    retries: int = 3,\n",
    "    timeout: int = PAGE_LOAD_TIMEOUT,\n",
    "    wait_until: str = \"domcontentloaded\",\n",
    "    retry_delay_ms: int = 1500,\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust page.goto with retry on timeout / navigation failure.\n",
    "    Returns True if navigation succeeds, False otherwise.\n",
    "    \"\"\"\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            await page.goto(url, wait_until=wait_until, timeout=timeout)\n",
    "            return True\n",
    "        except (PlaywrightTimeoutError, PlaywrightError) as e:\n",
    "            print(\n",
    "                f\"[WARN] goto failed (attempt {attempt}/{retries}) :: {url} :: {e}\"\n",
    "            )\n",
    "            log_soft_error(\n",
    "                CURRENT_COLLEGE_CONTEXT.get(\"college_name\"),\n",
    "                url,\n",
    "                f\"goto failed (attempt {attempt}/{retries}) :: {e}\"\n",
    "            )\n",
    "\n",
    "            if attempt < retries:\n",
    "                try:\n",
    "                    await page.wait_for_timeout(retry_delay_ms)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            else:\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            # unexpected error ‚Üí do not loop forever\n",
    "            print(f\"[ERROR] fatal goto error :: {url} :: {e}\")\n",
    "            return False\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "@asynccontextmanager\n",
    "async def page_task(page):\n",
    "    if getattr(page, \"_closing\", False) or page.is_closed():\n",
    "        yield False\n",
    "        return\n",
    "    page._active_tasks += 1\n",
    "    try:\n",
    "        yield True\n",
    "    finally:\n",
    "        page._active_tasks -= 1\n",
    "\n",
    "\n",
    "async def safe_close_page(page, timeout_ms=3000):\n",
    "    if page.is_closed():\n",
    "        return\n",
    "\n",
    "    # üîí signal shutdown\n",
    "    page._closing = True\n",
    "\n",
    "    # üîí stop response listeners if present\n",
    "    try:\n",
    "        if hasattr(page, \"_on_response\"):\n",
    "            page.remove_listener(\"response\", page._on_response)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # üîí wait for running tasks\n",
    "    waited = 0\n",
    "    while getattr(page, \"_active_tasks\", 0) > 0 and waited < timeout_ms:\n",
    "        await asyncio.sleep(0.05)\n",
    "        waited += 50\n",
    "\n",
    "    # üîí final close\n",
    "    try:\n",
    "        if not page.is_closed():\n",
    "            await page.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "async def visit_and_collect(page, depth, url, base_url, page_category):\n",
    "\n",
    "    # ------------------ SAFE NAVIGATION ------------------\n",
    "    ok = await goto_with_retry(\n",
    "        page,\n",
    "        url,\n",
    "        retries=3,\n",
    "        timeout=PAGE_LOAD_TIMEOUT,\n",
    "    )\n",
    "\n",
    "    if not ok:\n",
    "        print(f\"[ERROR] Failed after retries: {url}\")\n",
    "\n",
    "        log_soft_error(\n",
    "            CURRENT_COLLEGE_CONTEXT.get(\"college_name\"),\n",
    "            url,\n",
    "            \"Navigation failed after all retries (non-HTML resource)\"\n",
    "        )\n",
    "\n",
    "        return {c: [] for c in CATEGORY_KEYWORDS.keys()}\n",
    "\n",
    "    await safe_wait(page, 500)\n",
    "    await safe_load_wait(page)\n",
    "\n",
    "    # ------------------ PAGE STATE ------------------\n",
    "    page._seen_artifacts = {}\n",
    "    page._page_seen_urls = set()\n",
    "    page._clicked_elements = set()\n",
    "    page._local_seen_pdf = set()\n",
    "\n",
    "    # ------------------ GLOBAL DOM POISONING (SAFE) ------------------\n",
    "    await safe_evaluate(page, \"\"\"\n",
    "    () => {\n",
    "        document.querySelectorAll('*').forEach(el => {\n",
    "            try {\n",
    "                const cls = (el.className || '').toString().toLowerCase();\n",
    "                const aria = el.getAttribute && el.getAttribute('aria-roledescription');\n",
    "\n",
    "                if (\n",
    "                    aria === 'carousel' ||\n",
    "                    cls.includes('carousel') ||\n",
    "                    cls.includes('slider') ||\n",
    "                    cls.includes('owl-') ||\n",
    "                    cls.includes('swiper') ||\n",
    "                    cls.includes('slick')\n",
    "                ) {\n",
    "                    el.dataset.__crawler_skip = \"1\";\n",
    "                }\n",
    "            } catch(e){}\n",
    "        });\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    if depth>=1:\n",
    "        await safe_evaluate(page, \"\"\"\n",
    "        () => {\n",
    "            document.querySelectorAll('header, nav').forEach(el => {\n",
    "                el.dataset.__crawler_skip = \"1\";\n",
    "            });\n",
    "\n",
    "            document.querySelectorAll('*').forEach(el => {\n",
    "                try {\n",
    "                    const s = getComputedStyle(el);\n",
    "                    if ((s.position === 'fixed' || s.position === 'sticky')) {\n",
    "                        const r = el.getBoundingClientRect();\n",
    "                        if (r.top <= 80 && r.width > window.innerWidth * 0.6) {\n",
    "                            el.dataset.__crawler_skip = \"1\";\n",
    "                        }\n",
    "                    }\n",
    "                } catch(e){}\n",
    "            });\n",
    "        }\n",
    "        \"\"\")\n",
    "\n",
    "    category_links = {c: [] for c in CATEGORY_KEYWORDS}\n",
    "\n",
    "    # ------------------ NETWORK PDF CAPTURE ------------------\n",
    "    async def on_response(response):\n",
    "        if page._closing or page.is_closed():\n",
    "            return\n",
    "\n",
    "        async with page_task(page) as ok:\n",
    "            if not ok:\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                ct = (response.headers.get(\"content-type\") or \"\").lower()\n",
    "                if \"application/pdf\" in ct or response.url.lower().endswith(\".pdf\"):\n",
    "                    norm = normalize_url(response.url, \"\")\n",
    "                    page._local_seen_pdf.add(norm)\n",
    "                    upsert_artifact(\n",
    "                        page,\n",
    "                        norm,\n",
    "                        response.url,\n",
    "                        \"Network PDF\"\n",
    "                    )\n",
    "            except Exception:\n",
    "                return\n",
    "\n",
    "    # üîí keep reference so it can be removed safely\n",
    "    page._on_response = on_response\n",
    "    page.on(\"response\", on_response)\n",
    "\n",
    "    try:\n",
    "        # ------------------ PAGE SETTLING ------------------\n",
    "        await safe_wait(page, EXTRA_WAIT_MS)\n",
    "        await close_popups(page)\n",
    "        await opportunistic_close_popups(page)\n",
    "        await auto_scroll(page)\n",
    "\n",
    "        # ------------------ INTERACTION CONVERGENCE ------------------\n",
    "        for _ in range(10):\n",
    "            progress = False\n",
    "\n",
    "            for handler in (handle_tabs, handle_accordions, handle_dropdowns):\n",
    "                try:\n",
    "                    _, did = await handler(page, depth)\n",
    "                    if did:\n",
    "                        progress = True\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            if not progress:\n",
    "                break\n",
    "\n",
    "            await safe_wait(page, 300)\n",
    "\n",
    "        # ------------------ ANCHOR EXTRACTION ------------------\n",
    "        anchors = await page.query_selector_all(\"a[href]\")\n",
    "\n",
    "        for el in anchors:\n",
    "            try:\n",
    "                href = await safe_get_attr(el, \"href\")\n",
    "                if not href:\n",
    "                    continue\n",
    "\n",
    "                full = urljoin(page.url, href)\n",
    "                if not full.startswith((\"http://\", \"https://\")):\n",
    "                    continue\n",
    "\n",
    "                text = await safe_inner_text(el)\n",
    "                norm = normalize_url(full, \"\")\n",
    "\n",
    "                upsert_artifact(\n",
    "                    page,\n",
    "                    norm,\n",
    "                    full,\n",
    "                    text\n",
    "                )\n",
    "\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    finally:\n",
    "        page.remove_listener(\"response\", on_response)\n",
    "\n",
    "    # ------------------ FINAL STORE ------------------\n",
    "    for norm, obj in page._seen_artifacts.items():\n",
    "        accept_and_store(\n",
    "            raw_url=obj[\"raw\"],\n",
    "            enriched_text=obj[\"text\"] or \"Document\",\n",
    "            page_category=page_category,\n",
    "            category_links=category_links,\n",
    "            page=page,\n",
    "        )\n",
    "\n",
    "    return category_links\n",
    "\n",
    "'''\n",
    "    for frame in page.frames:\n",
    "        if frame.url.lower().endswith(\".pdf\"):\n",
    "            page._local_seen_pdf.add(normalize_url(frame.url, \"\"))\n",
    "        frame_url = frame.url or \"\"\n",
    "        norm = normalize_url(frame_url, \"\")\n",
    "        old = page._seen_artifacts.get(norm)\n",
    "\n",
    "        if should_accept_context(old, \"Network PDF\"):\n",
    "            page._seen_artifacts[norm] = \"Network PDF\"\n",
    "\n",
    "        try:\n",
    "            parsed = urlparse(frame_url)\n",
    "            for _, v in parse_qsl(parsed.query):\n",
    "                decoded = unquote(v)\n",
    "                if decoded.lower().endswith(\".pdf\"):\n",
    "                    raw_url = decoded\n",
    "                    enriched_text = \"Iframe Viewer PDF\"\n",
    "                    bucket, cat = classify_url(raw_url, enriched_text, page_category)\n",
    "\n",
    "                    # dedupe MUST still apply\n",
    "                    norm = normalize_url(raw_url, \"\")\n",
    "                    if norm in page._page_seen_urls:\n",
    "                        continue\n",
    "                    page._page_seen_urls.add(norm)\n",
    "\n",
    "                    if not accept_url(norm):\n",
    "                        continue\n",
    "\n",
    "                    category_links[cat].append((bucket, f\"{raw_url} || {enriched_text}\"))\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "    '''\n",
    "    # ===================== NETWORK PDF ASSIGNMENT =====================\n",
    "'''\n",
    "    for item in network_pdfs:\n",
    "        norm = normalize_url(item[\"url\"], \"\")\n",
    "        old = page._seen_artifacts.get(norm)\n",
    "        new_text = \"Network PDF\"\n",
    "\n",
    "        if should_accept_context(old, new_text):\n",
    "            page._seen_artifacts[norm] = new_text\n",
    "            assign_category(\n",
    "                category_links,\n",
    "                url=item[\"url\"],\n",
    "                text=new_text,\n",
    "                depth=depth,\n",
    "                page_category=page_category,\n",
    "            )\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def matches_category(cat: str, text: str, url: str) -> bool:\n",
    "    combined = f\"{text} {url}\".lower()\n",
    "    return any(kw in combined for kw in CATEGORY_KEYWORDS.get(cat, []))\n",
    "'''\n",
    "\n",
    "def matches_category_own(cat: str, text: str, url: str) -> bool:\n",
    "    combined = f\"{text} {url}\".lower()\n",
    "    for kw in CATEGORY_KEYWORDS.get(cat, []):\n",
    "        if kw and kw in combined:\n",
    "            return True\n",
    "    return False\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "ACADEMIC_TLDS = {\n",
    "    \"ac\", \"edu\", \"org\", \"gov\", \"in\"\n",
    "}\n",
    "\n",
    "def extract_domain_token(base_url: str) -> str | None:\n",
    "    try:\n",
    "        netloc = urlparse(base_url).netloc.lower().lstrip(\"www.\")\n",
    "        parts = netloc.split(\".\")\n",
    "\n",
    "        # Example:\n",
    "        # nitk.ac.in ‚Üí [\"nitk\",\"ac\",\"in\"]\n",
    "        # bits-pilani.ac.in ‚Üí [\"bits-pilani\",\"ac\",\"in\"]\n",
    "        # rcciit.org ‚Üí [\"rcciit\",\"org\"]\n",
    "\n",
    "        if len(parts) >= 3 and parts[-2] in ACADEMIC_TLDS:\n",
    "            token = parts[-3]\n",
    "        else:\n",
    "            token = parts[0]\n",
    "\n",
    "        # normalize: remove hyphens, dots\n",
    "        token = re.sub(r\"[^a-z0-9]\", \"\", token)\n",
    "\n",
    "        return token or None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# üö´ NEVER useful for accreditation\n",
    "HARD_BLOCK_DOMAINS = {\n",
    "    \"youtube\", \"youtu.be\",\n",
    "    \"facebook\", \"fb.com\",\n",
    "    \"instagram\",\n",
    "    \"twitter\", \"x.com\",\n",
    "    \"linkedin\",\n",
    "    \"bing\",\n",
    "    \"wikipedia\",\n",
    "    \"telegram\",\n",
    "    \"whatsapp\",\n",
    "    \"nirfindia.org\",\n",
    "    \"nbaind.org\",\n",
    "    \"mhrd.gov.in\",\n",
    "    \"shiksha.com\",\n",
    "    \"collegedunia.com\",\n",
    "    \"careers360.com\",\n",
    "    \"indiastudychannel.com\",\n",
    "    \"examresults.net\",\n",
    "    \"entranceexam.net\" ,\n",
    "    \"naac.gov\",\n",
    "    \"nbaind.org\",\n",
    "    \"nirf.gov\",\n",
    "    \"ugc.ac\",\n",
    "    \"aicte-india.org\"\n",
    "}\n",
    "\n",
    "# ‚ö†Ô∏è External hosts that MAY contain valid docs\n",
    "SOFT_EXTERNAL_HOSTS = {\n",
    "    \"docs.google\",\n",
    "    \"drive.google\",\n",
    "    \"googleusercontent\",\n",
    "    \"onedrive.live\",\n",
    "    \"sharepoint\",\n",
    "    \"dropbox\",\n",
    "    \"box.com\"\n",
    "}\n",
    "\n",
    "\n",
    "ACADEMIC_KEYWORDS = {\n",
    "    \"naac\",\n",
    "    \"iqac\",\n",
    "    \"nirf\",\n",
    "    \"aicte\",\n",
    "    \"nba\",\n",
    "    \"ariia\",\n",
    "    \"aqar\",\n",
    "    \"accreditation\",\n",
    "    \"approval\",\n",
    "    \"extension of approval\",\n",
    "    \"mandatory disclosure\"\n",
    "}\n",
    "def should_enqueue_url(\n",
    "    url: str,\n",
    "    text: str,\n",
    "    institution_token: str\n",
    ") -> bool:\n",
    "    combined = f\"{url} {text}\".lower()\n",
    "\n",
    "    # 1Ô∏è‚É£ HARD BLOCK (always useless)\n",
    "    for bad in HARD_BLOCK_DOMAINS:\n",
    "        if bad in combined:\n",
    "            return False\n",
    "\n",
    "    # 2Ô∏è‚É£ Normalize for ownership checks\n",
    "    normalized = re.sub(r\"[^a-z0-9]\", \"\", combined)\n",
    "\n",
    "    # 3Ô∏è‚É£ College ownership (strongest signal)\n",
    "    if institution_token and institution_token in normalized:\n",
    "        return True\n",
    "\n",
    "    # 4Ô∏è‚É£ Academic relevance keywords\n",
    "    academic_hit = any(kw in combined for kw in ACADEMIC_KEYWORDS)\n",
    "\n",
    "    # 5Ô∏è‚É£ Soft external hosts (Google Docs, Drive, etc.)\n",
    "    if any(h in combined for h in SOFT_EXTERNAL_HOSTS):\n",
    "        # allow ONLY if academically relevant\n",
    "        return academic_hit\n",
    "\n",
    "    # 6Ô∏è‚É£ Non-soft external ‚Üí allow only if academic keyword exists\n",
    "    if academic_hit:\n",
    "        return True\n",
    "\n",
    "    # ‚ùå Otherwise skip\n",
    "    return False\n",
    "\n",
    "\n",
    "# ------------------------- CORE PROCESSING -------------------------\n",
    "def college_to_filename(college_name: str) -> Path:\n",
    "    safe = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", college_name).strip(\"_\")\n",
    "    return OUTPUT_DIR / f\"college_info_{safe}.xlsx\"\n",
    "def chunk_list(items, max_chars=30000):\n",
    "    chunk, chunks = \"\", []\n",
    "    for it in items:\n",
    "        if len(chunk) + len(it) + 1 > max_chars:\n",
    "            chunks.append(chunk)\n",
    "            chunk = it\n",
    "        else:\n",
    "            chunk += (\"\\n\" if chunk else \"\") + it\n",
    "    if chunk:\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def save_progress_excel(output_file):\n",
    "    \"\"\"\n",
    "    Persist PROGRESS_ROWS to Excel.\n",
    "    - Appends rows logically via PROGRESS_ROWS rebuild\n",
    "    - No CSV\n",
    "    - No column splitting\n",
    "    - Safe for large PDF lists (handled earlier via row chunking)\n",
    "    \"\"\"\n",
    "    if not PROGRESS_ROWS:\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(list(PROGRESS_ROWS.values()))\n",
    "\n",
    "    # ---- Stable column ordering ----\n",
    "    base_cols = []\n",
    "    for c in (\"college_name\", \"base_url\", \"depth\", \"row_type\"):\n",
    "        if c in df.columns:\n",
    "            base_cols.append(c)\n",
    "\n",
    "    link_cols = sorted(\n",
    "        c for c in df.columns\n",
    "        if c.endswith(\"_links\") and c not in base_cols\n",
    "    )\n",
    "\n",
    "    other_cols = [c for c in df.columns if c not in base_cols + link_cols]\n",
    "\n",
    "    ordered_cols = base_cols + link_cols + other_cols\n",
    "\n",
    "    try:\n",
    "        df = df[ordered_cols]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # ---- Write Excel ONLY ----\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"[PROGRESS] Updated {output_file} \"\n",
    "        f\"with {len(df)} row(s).\"\n",
    "    )\n",
    "\n",
    "DOCUMENT_BUCKETS = {\n",
    "    \"pdf\": \"pdf\",\n",
    "    \"excel\": \"excel\",\n",
    "    \"word\": \"word\",\n",
    "    \"ppt\": \"ppt\",\n",
    "    \"archive\": \"archive\",\n",
    "    \"google_drive\": \"google_drive\",\n",
    "    \"other_document\": \"other_document\",\n",
    "    \"images\":\"images\",\n",
    "}\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def create_empty_college_excel(college_name: str, base_url: str):\n",
    "    \"\"\"\n",
    "    Create an empty Excel file with correct columns for a college.\n",
    "    This guarantees the file exists even if no rows are ever written.\n",
    "    \"\"\"\n",
    "    output_file = college_to_filename(college_name)\n",
    "\n",
    "    # Build empty row structure (headers only)\n",
    "    cols = [\"college_name\", \"base_url\", \"depth\", \"row_type\"]\n",
    "    cols += [f\"{c}_links\" for c in CATEGORY_KEYWORDS.keys()]\n",
    "\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    # Optional: keep college metadata visible even if empty\n",
    "    # (comment out if you prefer a fully empty sheet)\n",
    "    # df.loc[0, \"college_name\"] = college_name\n",
    "    # df.loc[0, \"base_url\"] = base_url\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(f\"[INIT] Created empty Excel: {output_file}\")\n",
    "\n",
    "\n",
    "async def process_college(browser, college_name: str, base_url: str):\n",
    "    print(f\"\\n[COLLEGE] Starting processing: {college_name} | {base_url}\")\n",
    "    \n",
    "    # ‚úÖ CREATE EMPTY EXCEL IMMEDIATELY\n",
    "    create_empty_college_excel(college_name, base_url)\n",
    "\n",
    "    global PROGRESS_ROWS\n",
    "    #GLOBAL_SEEN_URLS.clear()\n",
    "    GLOBAL_SEEN_ARTIFACTS.clear()\n",
    "    GLOBAL_SEEN_PAGES.clear()\n",
    "    GLOBAL_EXCEL_URLS.clear()\n",
    "    GLOBAL_BFS_URLS.clear()\n",
    "\n",
    "    last_flushed_depth = -1\n",
    "    '''\n",
    "    # üîí GLOBAL URL OWNERSHIP (single source of truth)\n",
    "    global GLOBAL_URL_OWNERS\n",
    "    GLOBAL_URL_OWNERS.clear()\n",
    "    '''\n",
    "\n",
    "    #browser = await playwright.chromium.launch(headless=HEADLESS)\n",
    "    #page = await browser.new_page( viewport={\"width\": 1920, \"height\": 1080})\n",
    "\n",
    "    output_file = college_to_filename(college_name)\n",
    "    visited_pages = set()          # pages already crawled\n",
    "   \n",
    "    queued_pages = set()\n",
    "\n",
    "    start_url = base_url\n",
    "    start_norm = normalize_url(start_url, \"\")\n",
    "    #queue = [(start_url, 0, None)]\n",
    "    queue = deque([(start_url, 0, None)])\n",
    "    queued_pages.add(start_norm)\n",
    "    #GLOBAL_SEEN_URLS.add(start_norm)\n",
    "    GLOBAL_SEEN_PAGES.add(start_norm)\n",
    "    start_canon = canonicalize_for_dedupe(start_norm)\n",
    "    GLOBAL_BFS_URLS.add(start_canon)\n",
    "\n",
    "\n",
    "\n",
    "    # depth -> category -> row_type -> set(entries)\n",
    "    all_links_by_depth = {}\n",
    "\n",
    "    def ensure_depth_struct(d):\n",
    "        if d not in all_links_by_depth:\n",
    "            all_links_by_depth[d] = {\n",
    "                c: {\n",
    "                    \"nonpdf_category_related\": set(),\n",
    "                    \"nonpdf_other\": set(),\n",
    "                    \"pdf\": set(),\n",
    "                    \"excel\": set(),\n",
    "                    \"word\": set(),\n",
    "                    \"ppt\": set(),\n",
    "                    \"archive\": set(),\n",
    "                    \"google_drive\": set(),\n",
    "                    \"other_document\": set(),\n",
    "                    \"images\": set(),  # ‚úÖ ADD THIS\n",
    "                }\n",
    "                for c in CATEGORY_KEYWORDS.keys()\n",
    "            }\n",
    "\n",
    "\n",
    "    def build_rows():\n",
    "        rows = []\n",
    "\n",
    "        for depth, cats in sorted(all_links_by_depth.items()):\n",
    "            for rt in sorted({\n",
    "                rt for cats in all_links_by_depth.values()\n",
    "                for cat in cats.values()\n",
    "                for rt in cat.keys()\n",
    "                if rt != \"nonpdf_other\" #can include if needed\n",
    "            }): \n",
    "\n",
    "                # process each category independently\n",
    "                for c in CATEGORY_KEYWORDS:\n",
    "                    items = sorted(cats[c].get(rt, ()))\n",
    "                    if not items:\n",
    "                        continue\n",
    "\n",
    "                    chunks = chunk_list(items)\n",
    "\n",
    "                    for chunk in chunks:\n",
    "                        row = {\n",
    "                            \"college_name\": college_name,\n",
    "                            \"base_url\": base_url,\n",
    "                            \"depth\": depth,\n",
    "                            \"row_type\": rt,\n",
    "                        }\n",
    "\n",
    "                        # initialize all link columns empty\n",
    "                        for col in CATEGORY_KEYWORDS:\n",
    "                            row[f\"{col}_links\"] = \"\"\n",
    "\n",
    "                        # only this category gets data\n",
    "                        row[f\"{c}_links\"] = chunk\n",
    "\n",
    "                        rows.append(row)\n",
    "\n",
    "        return rows\n",
    "\n",
    "    # ===================== BFS =====================\n",
    "    while queue:\n",
    "        #current_url, depth, page_category = queue.pop(0)\n",
    "        current_url, depth, page_category = queue.popleft()\n",
    "        norm_current = normalize_url(current_url, \"\")\n",
    "\n",
    "        if norm_current in visited_pages :\n",
    "            continue\n",
    "        # must already be globally accepted\n",
    "        '''\n",
    "        if norm_current not in GLOBAL_SEEN_PAGES:\n",
    "            continue\n",
    "        '''\n",
    "\n",
    "        visited_pages.add(norm_current)\n",
    "\n",
    "        print(f\"[INFO] Visiting depth {depth}: {current_url}\")\n",
    "\n",
    "        # üîí UPDATE CONTEXT FOR PAGE-LEVEL ERRORS\n",
    "        CURRENT_COLLEGE_CONTEXT[\"url\"] = current_url\n",
    "\n",
    "        page = await browser.new_page(viewport={\"width\": 1920, \"height\": 1080})\n",
    "        # üîí lifecycle guards (MANDATORY)\n",
    "        page._closing = False\n",
    "        page._active_tasks = 0\n",
    "\n",
    "        try:\n",
    "            # visit_and_collect returns: { category -> list[(bucket, entry)] }\n",
    "            cat_links = await visit_and_collect(\n",
    "                page, depth, current_url, base_url, page_category\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipping page due to error: {current_url}\")\n",
    "            log_college_error(college_name, current_url, e)\n",
    "            continue\n",
    "        finally:\n",
    "            await safe_close_page(page)\n",
    "\n",
    "        ensure_depth_struct(depth)\n",
    "\n",
    "        # ---------- INSERT INTO EXCEL STRUCTURE ----------\n",
    "        for cat, items in cat_links.items():\n",
    "            for bucket,entry in items:\n",
    "                parts = [p.strip() for p in entry.split(\"||\", 1)]\n",
    "                url = parts[0]\n",
    "                text = parts[1] if len(parts) > 1 else \"\"\n",
    "\n",
    "                url = url.strip()\n",
    "                text = text.strip()\n",
    "\n",
    "                canon = canonicalize_for_dedupe(url)\n",
    "\n",
    "                # üîí FINAL EXCEL DEDUPE\n",
    "                if canon in GLOBAL_EXCEL_URLS:\n",
    "                    continue\n",
    "\n",
    "                GLOBAL_EXCEL_URLS.add(canon)\n",
    "\n",
    "                # bucket already decided earlier ‚Äî NO re-classification\n",
    "                # üîç Classify at ROW CREATION TIME\n",
    "                if bucket in DOCUMENT_BUCKETS:\n",
    "                    all_links_by_depth[depth][cat][bucket].add(entry)\n",
    "                else:\n",
    "                    # non-document logic stays unchanged\n",
    "                    if bucket == \"nonpdf_category_related\":\n",
    "                        all_links_by_depth[depth][cat][\"nonpdf_category_related\"].add(entry)\n",
    "                    else:\n",
    "                        all_links_by_depth[depth][cat][\"nonpdf_other\"].add(entry)\n",
    "\n",
    "        # ================== INCREMENTAL DEPTH FLUSH ==================\n",
    "\n",
    "        # üîí FORCE FLUSH EVEN IF NO BFS ENQUEUE\n",
    "        # If this page produced ANY stored artifacts, write them immediately\n",
    "\n",
    "        produced_any = any(\n",
    "            all_links_by_depth[depth][c][rt]\n",
    "            for c in CATEGORY_KEYWORDS\n",
    "            for rt in all_links_by_depth[depth][c]\n",
    "        )\n",
    "\n",
    "        if produced_any and depth >= last_flushed_depth:\n",
    "            new_rows = []\n",
    "\n",
    "            for rt in (\n",
    "                \"pdf\", \"excel\", \"word\", \"ppt\",\n",
    "                \"archive\", \"google_drive\", \"other_document\",\n",
    "                \"images\", \"nonpdf_category_related\"\n",
    "            ):\n",
    "                for c in CATEGORY_KEYWORDS:\n",
    "                    items = sorted(all_links_by_depth[depth][c].get(rt, ()))\n",
    "                    if not items:\n",
    "                        continue\n",
    "\n",
    "                    for chunk in chunk_list(items):\n",
    "                        row = {\n",
    "                            \"college_name\": college_name,\n",
    "                            \"base_url\": base_url,\n",
    "                            \"depth\": depth,\n",
    "                            \"row_type\": rt,\n",
    "                        }\n",
    "                        for col in CATEGORY_KEYWORDS:\n",
    "                            row[f\"{col}_links\"] = \"\"\n",
    "                        row[f\"{c}_links\"] = chunk\n",
    "                        new_rows.append(row)\n",
    "\n",
    "            if new_rows:\n",
    "                start = len(PROGRESS_ROWS)\n",
    "                for i, r in enumerate(new_rows, start=start):\n",
    "                    PROGRESS_ROWS[f\"{college_name}___{i}\"] = r\n",
    "\n",
    "                save_progress_excel(output_file)\n",
    "\n",
    "            last_flushed_depth = depth\n",
    "\n",
    "        # ---------- QUEUE EXPANSION ----------\n",
    "        for category in CATEGORY_KEYWORDS.keys():\n",
    "            for entry in all_links_by_depth[depth][category][\"nonpdf_category_related\"]:\n",
    "                parts = entry.split(\"||\", 1)\n",
    "                url = entry.split(\"||\")[0].strip()\n",
    "                text = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "                \n",
    "                # üîí HARD STOP: never crawl documents\n",
    "                doc_type = classify_document_url(url)\n",
    "                if doc_type:\n",
    "                    continue\n",
    "                \n",
    "                # üîí HARD STOP: never crawl binary / media URLs\n",
    "                if is_non_crawlable_url(url):\n",
    "                    continue\n",
    "\n",
    "                if is_pdf(url):\n",
    "                    continue\n",
    "                \n",
    "                institution_token = extract_domain_token(base_url)\n",
    "\n",
    "                if not should_enqueue_url(\n",
    "                    url=url,\n",
    "                    text=text,\n",
    "                    institution_token=institution_token\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "\n",
    "                '''\n",
    "                # üîí CRITICAL: enforce intrinsic category match\n",
    "                if not matches_category_own(category, text, url):\n",
    "                    continue\n",
    "                '''\n",
    "                norm = normalize_url(url, \"\")\n",
    "                if norm in visited_pages or norm in queued_pages:\n",
    "                    continue\n",
    "\n",
    "                # üîí IQAC ADMIN PAGE ‚Äî extract but DO NOT enqueue\n",
    "                if category == \"iqac\":\n",
    "                    if is_iqac_admin_page(f\"{url} {text}\"):\n",
    "                        continue  # ‚ùå skip BFS enqueue only\n",
    "\n",
    "                canon = canonicalize_for_dedupe(url)\n",
    "                # üîí FINAL BFS DEDUPE\n",
    "                if canon in GLOBAL_BFS_URLS:\n",
    "                    continue\n",
    "\n",
    "                GLOBAL_BFS_URLS.add(canon)\n",
    "\n",
    "                queue.append((url, depth + 1, category))\n",
    "                queued_pages.add(norm)\n",
    "                #GLOBAL_SEEN_PAGES.add(norm)\n",
    "\n",
    "\n",
    "    #await browser.close()\n",
    "    return build_rows()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------- EXCEL HELPERS -------------------------\n",
    "\n",
    "\n",
    "def build_row_dict(college_name: str, base_url: str, all_category_links: dict) -> dict:\n",
    "    def join_sorted(s):\n",
    "        return \"\\n\".join(sorted(s)) if s else \"\"\n",
    "    return {\n",
    "        \"college_name\": college_name,\n",
    "        \"base_url\": base_url,\n",
    "        \"mandatory_disclosure_links\": join_sorted(all_category_links.get(\"mandatory_disclosure\", set())),\n",
    "        \"naac_links\": join_sorted(all_category_links.get(\"naac\", set())),\n",
    "        \"nba_links\": join_sorted(all_category_links.get(\"nba\", set())),\n",
    "        \"nirf_links\": join_sorted(all_category_links.get(\"nirf\", set())),\n",
    "        \"iqac_links\": join_sorted(all_category_links.get(\"iqac\", set())),\n",
    "        \"aicte_links\": join_sorted(all_category_links.get(\"aicte\", set())),\n",
    "        \"aqar_links\": join_sorted(all_category_links.get(\"aqar\", set())),\n",
    "        \"ariia_links\": join_sorted(all_category_links.get(\"ariia\", set())),\n",
    "        \"accreditation_links\": join_sorted(all_category_links.get(\"accreditation\", set())),\n",
    "        \"criteria_links\": join_sorted(all_category_links.get(\"criteria\", set())),\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7593f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDocstring for source_links_extractio_from_url_2_0 copy 6-final.ipynb\\n\\n\\nsudo apt update\\nsudo apt install python3.12-venv\\n\\npython3 -m venv .venv\\n\\nsource .venv/bin/activate\\n\\npip install pandas playwright openpyxl\\n\\nplaywright install\\n\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Docstring for source_links_extractio_from_url_2_0 copy 6-final.ipynb\n",
    "\n",
    "\n",
    "sudo apt update\n",
    "sudo apt install python3.12-venv\n",
    "\n",
    "python3 -m venv .venv\n",
    "\n",
    "source .venv/bin/activate\n",
    "\n",
    "pip install pandas playwright openpyxl\n",
    "\n",
    "playwright install\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256b7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30e5d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_colleges_from_excel(excel_path, sheet_name=\"Sheet1\"):\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "\n",
    "    required_cols = {\"College Name\", \"College Website URL\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(\n",
    "            f\"Excel must contain columns: {required_cols}. Found: {df.columns}\"\n",
    "        )\n",
    "\n",
    "    colleges = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name = str(row[\"College Name\"]).strip()\n",
    "        url = str(row[\"College Website URL\"]).strip()\n",
    "\n",
    "        if not name or not url or url.lower() == \"nan\":\n",
    "            continue\n",
    "\n",
    "        colleges.append({\n",
    "            \"college_name\": name,\n",
    "            \"base_url\": url\n",
    "        })\n",
    "\n",
    "    print(f\"[INFO] Loaded {len(colleges)} colleges from Excel\")\n",
    "    return colleges\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------- RUNNER -------------------------\n",
    "async def run_scraping(colleges):\n",
    "    setup_asyncio_exception_logger()\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=HEADLESS)\n",
    "\n",
    "        for c in colleges:\n",
    "            global PROGRESS_ROWS\n",
    "            PROGRESS_ROWS = {}\n",
    "\n",
    "            name = c.get(\"college_name\")\n",
    "            url = c.get(\"base_url\")\n",
    "\n",
    "            # üîí UPDATE GLOBAL CONTEXT\n",
    "            CURRENT_COLLEGE_CONTEXT[\"college_name\"] = name\n",
    "            CURRENT_COLLEGE_CONTEXT[\"url\"] = url\n",
    "            \n",
    "            if not name or not url:\n",
    "                print(f\"[WARN] Skipping invalid entry: {c}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                await process_college(browser, name, url)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed college: {name}\")\n",
    "                print(f\"[ERROR] URL: {url}\")\n",
    "                print(f\"[ERROR] Logged to file.\")\n",
    "\n",
    "                log_college_error(name, url, e)\n",
    "                continue\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    print(\"[DONE] All colleges processed.\")\n",
    "\n",
    "\n",
    "async def run_scraping_from_excel():\n",
    "    colleges = load_colleges_from_excel(\n",
    "        EXCEL_INPUT_FILE,\n",
    "        sheet_name=SHEET_NAME\n",
    "    )\n",
    "    await run_scraping(colleges)\n",
    "\n",
    "\n",
    "    '''\n",
    "        async with async_playwright() as p:\n",
    "            browser = await p.chromium.launch(headless=HEADLESS)\n",
    "\n",
    "            for c in colleges:\n",
    "                global PROGRESS_ROWS\n",
    "                PROGRESS_ROWS = {}\n",
    "\n",
    "                name = c[\"college_name\"]\n",
    "                url = c[\"base_url\"]\n",
    "\n",
    "                print(f\"\\n[INFO] Processing: {name}\")\n",
    "                try:\n",
    "                    await process_college(browser, name, url)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed college: {name}\")\n",
    "                    print(f\"[ERROR] URL: {url}\")\n",
    "                    print(f\"[ERROR] Logged to file.\")\n",
    "\n",
    "                    log_college_error(name, url, e)\n",
    "                    continue\n",
    "\n",
    "            await browser.close()\n",
    "\n",
    "        print(\"[DONE] All colleges processed.\")\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "# ------------------------- USAGE EXAMPLE -------------------------\n",
    "# example = [{\"college_name\": \"Guru Nanak Institute of Technology\", \"base_url\": \"https://www.gnithyd.ac.in/\"}]\n",
    "# df = asyncio.run(run_scraping(example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a008103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[COLLEGE] Starting processing: test | https://www.mckvie.edu.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_test/college_info_test.xlsx\n",
      "[INFO] Visiting depth 0: https://www.mckvie.edu.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/mandatory-disclosure/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/naac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 11 row(s).\n",
      "[INFO] Visiting depth 1: https://mckvie.edu.in/affiliations-accreditations/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 14 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/nirf/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 18 row(s).\n",
      "[INFO] Visiting depth 1: https://www.mckvie.edu.in/iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 23 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/aicte-feedback/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/ariia/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 36 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/affiliations-accreditations-approvals/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 44 row(s).\n",
      "[INFO] Visiting depth 2: https://mckvie.edu.in/video-of-naac-peer-team-visit-held-on-13-10-2017-and-14-10-2017/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 2: http://www.mckvie.edu.in/ssr/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 45 row(s).\n",
      "[INFO] Visiting depth 2: http://www.mckvie.edu.in/aqar/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 47 row(s).\n",
      "[INFO] Visiting depth 2: http://www.mckvie.edu.in/contact-iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 49 row(s).\n",
      "[INFO] Visiting depth 2: https://www.mckvie.edu.in/aicte-approvals/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 52 row(s).\n",
      "[INFO] Visiting depth 2: https://www.mckvie.edu.in/nba-accreditations/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 55 row(s).\n",
      "[INFO] Visiting depth 3: https://www.mckvie.edu.in/aqar-supplimentary-docs/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_test/college_info_test.xlsx with 59 row(s).\n",
      "[DONE] All colleges processed.\n"
     ]
    }
   ],
   "source": [
    "example = [\n",
    "     {\n",
    "        \"college_name\": \"test\",\n",
    "        \"base_url\": \"https://www.mckvie.edu.in/\",\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "df = await run_scraping(example)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a93702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 177 colleges from Excel\n",
      "\n",
      "[COLLEGE] Starting processing: Jalpaiguri Government Engineering College | http://jgec.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Jalpaiguri_Government_Engineering_College.xlsx\n",
      "[INFO] Visiting depth 0: http://jgec.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Jalpaiguri_Government_Engineering_College.xlsx with 6 row(s).\n",
      "[INFO] Visiting depth 1: https://jgec.ac.in/announcement/2\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Jalpaiguri_Government_Engineering_College.xlsx with 15 row(s).\n",
      "[INFO] Visiting depth 1: https://jgec.ac.in/announcement/5\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Jalpaiguri_Government_Engineering_College.xlsx with 25 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: Kalyani Government Engineering College | https://www.kgec.edu.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx\n",
      "[INFO] Visiting depth 0: https://www.kgec.edu.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[DEBUG] Scroll round 3/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 4 row(s).\n",
      "[INFO] Visiting depth 1: https://www.kgec.edu.in/naac\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 6 row(s).\n",
      "[INFO] Visiting depth 1: https://www.kgec.edu.in/iqac\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 10 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=10\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 11 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=3\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 12 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=6\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 13 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naacrecognition\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 14 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=2\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 15 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=1\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 16 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=4\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 17 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=11\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 18 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=5\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 19 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=7\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 20 row(s).\n",
      "[INFO] Visiting depth 2: https://www.kgec.edu.in/naac-metadata/naactype?id=12\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Kalyani_Government_Engineering_College.xlsx with 21 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: Haldia Institute Of Technology | http://hithaldia.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Haldia_Institute_Of_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://hithaldia.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Haldia_Institute_Of_Technology.xlsx with 18 row(s).\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/dvv/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/ece-nba-documents/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/aeie-nba-documents/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/ee-nba-documents/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/nirf-data/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: https://hitaicteidealab.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Haldia_Institute_Of_Technology.xlsx with 20 row(s).\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/aicte-approval-year-wise/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Haldia_Institute_Of_Technology.xlsx with 22 row(s).\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/aqar-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Haldia_Institute_Of_Technology.xlsx with 24 row(s).\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/accreditation-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Haldia_Institute_Of_Technology.xlsx with 26 row(s).\n",
      "[INFO] Visiting depth 1: https://hithaldia.ac.in/university-affiliation/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Haldia_Institute_Of_Technology.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://hitaicteidealab.com/\n",
      "[WARN] goto failed (attempt 1/3) :: https://hitaicteidealab.com/ :: Page.goto: net::ERR_NAME_NOT_RESOLVED at https://hitaicteidealab.com/\n",
      "Call log:\n",
      "  - navigating to \"https://hitaicteidealab.com/\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[WARN] goto failed (attempt 2/3) :: https://hitaicteidealab.com/ :: Page.goto: net::ERR_NAME_NOT_RESOLVED at https://hitaicteidealab.com/\n",
      "Call log:\n",
      "  - navigating to \"https://hitaicteidealab.com/\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[WARN] goto failed (attempt 3/3) :: https://hitaicteidealab.com/ :: Page.goto: net::ERR_NAME_NOT_RESOLVED at https://hitaicteidealab.com/\n",
      "Call log:\n",
      "  - navigating to \"https://hitaicteidealab.com/\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[ERROR] Failed after retries: https://hitaicteidealab.com/\n",
      "\n",
      "[COLLEGE] Starting processing: Institute Of Engineering & Management | http://iem.edu.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx\n",
      "[INFO] Visiting depth 0: http://iem.edu.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 8 row(s).\n",
      "[INFO] Visiting depth 1: https://iem.edu.in/naac-ssr/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: https://naac.iem.edu.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 12 row(s).\n",
      "[INFO] Visiting depth 1: https://iem.edu.in/nirf/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 16 row(s).\n",
      "[INFO] Visiting depth 1: https://iem.edu.in/news-events/iems-business-school-is-now-a-member-of-the-prestigious-iacbe-international-accreditation-council-for-business-education/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 20 row(s).\n",
      "[INFO] Visiting depth 2: https://naac.iem.edu.in/action-taken-report/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 21 row(s).\n",
      "[INFO] Visiting depth 2: https://naac.iem.edu.in/committee/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 22 row(s).\n",
      "[INFO] Visiting depth 2: https://naac.iem.edu.in/mandate/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 23 row(s).\n",
      "[INFO] Visiting depth 2: https://naac.iem.edu.in/aqara-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 32 row(s).\n",
      "[INFO] Visiting depth 2: https://naac.iem.edu.in/aqar-2021-22-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 41 row(s).\n",
      "[INFO] Visiting depth 2: https://naac.iem.edu.in/aqara-2022-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 53 row(s).\n",
      "[INFO] Visiting depth 2: https://naac.iem.edu.in/mom/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 65 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/aqar-part-a/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 69 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion7-2020-21\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 74 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criteria-1-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 80 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-2-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 88 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-3-2020-21\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 99 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-4-2020-21\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 112 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-5-2020-21\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 125 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-6-2020-21\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 140 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/aqar-22part-b/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 155 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 170 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-5/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 186 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-6/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 202 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 218 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion7/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 234 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/aqar-criterion-4-1-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 250 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion7-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 267 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 284 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/aqar-23part-b/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 305 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-6-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 327 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 349 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-5-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 372 row(s).\n",
      "[INFO] Visiting depth 3: https://naac.iem.edu.in/criterion-4-1-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 396 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion-1-1/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 399 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-20part-b/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 402 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 406 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 410 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 414 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7-3-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 418 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7-2-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 423 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-4-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 428 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-3-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 433 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-2-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 438 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-5-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 443 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-6-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 449 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-3-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 455 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-7-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 462 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-4-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 469 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-2-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 476 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-5-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 484 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-4-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 493 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-2-2020-21\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 502 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-3-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 511 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-2-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 521 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-4-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 531 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-3-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 541 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-4-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 552 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-3-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 563 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-5-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 575 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-2-2020-21/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 587 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-5/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 599 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 611 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-6/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 623 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 635 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 647 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-7/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 659 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion5-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 671 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion5-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 683 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion5-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 696 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 709 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-5/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 722 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 735 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 748 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 761 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-5/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 774 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-6/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 787 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-7/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 800 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 813 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 826 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7/principal@iemcal.com\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 839 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7/sanghamitra@iemcal.com\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 852 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7-3-22/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 865 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 878 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 891 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 904 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 917 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 930 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion7-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 943 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 956 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-5-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 969 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 982 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-7-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 995 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-6-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1008 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion3-4-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1021 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/bos-mom/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1034 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1049 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-4-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1065 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/aqar-criterion-1-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1081 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-4-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1097 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1114 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-5-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1133 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion6-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1154 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1178 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-4-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1202 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-7-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1226 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-5-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1250 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1274 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion2-6-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1298 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion5-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1322 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion5-4-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1346 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion5-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1370 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-3-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1394 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-2-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1418 row(s).\n",
      "[INFO] Visiting depth 4: https://naac.iem.edu.in/criterion4-4-23/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1442 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-3-1/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1443 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-6-1/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1445 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-1-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1449 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-1-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1453 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-7-1/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1458 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-4-1/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1464 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-1-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1470 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-2-1/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1476 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-5-1/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1484 row(s).\n",
      "[INFO] Visiting depth 5: https://naac.iem.edu.in/criterion-2-2020-2021/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1492 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-3-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1494 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-3-5/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1496 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-3-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1498 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-3-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1500 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-6-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1504 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-6-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1508 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-6-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1512 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-6-5/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1516 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-7-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1520 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-7-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1524 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-4-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1529 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-4-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1534 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-4-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1539 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-5-4/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1545 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-5-2/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1553 row(s).\n",
      "[INFO] Visiting depth 6: https://naac.iem.edu.in/criterion-5-3/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Institute_Of_Engineering_Management.xlsx with 1561 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: Bankura Unnayani Institute Of Engineering | http://www.buie.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx\n",
      "[INFO] Visiting depth 0: http://www.buie.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 7 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/infrastructure/mandatory-disclosure\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 8 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/nirf\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 10 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/about-iqac\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 13 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/notice\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 17 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/criterion-v\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 21 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/criterion-vii\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 25 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/criterion-iii\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/criterion-i\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 33 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/criterion-iv\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 37 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/criterion-vi\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 41 row(s).\n",
      "[INFO] Visiting depth 1: http://www.buie.ac.in/iqac/criterion-ii\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 45 row(s).\n",
      "[INFO] Visiting depth 2: http://www.buie.ac.in/iqac\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bankura_Unnayani_Institute_Of_Engineering.xlsx with 46 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: Murshidabad College Of Engineering & Technology | http://www.mcetbhb.net/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Murshidabad_College_Of_Engineering_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://www.mcetbhb.net/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Murshidabad_College_Of_Engineering_Technology.xlsx with 4 row(s).\n",
      "[INFO] Visiting depth 1: https://www.mcetbhb.net/disclosure\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: http://makautexam.net/aicte_details/aicteugdetails.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Murshidabad_College_Of_Engineering_Technology.xlsx with 6 row(s).\n",
      "[INFO] Visiting depth 1: https://www.mcetbhb.net/affiliation\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Murshidabad_College_Of_Engineering_Technology.xlsx with 9 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: College Of Engineering & Management, Kolaghat | http://www.cemkolaghat.org/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_College_Of_Engineering_Management_Kolaghat.xlsx\n",
      "[INFO] Visiting depth 0: http://www.cemkolaghat.org/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Asansol Engineering College | http://www.aecwb.edu.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Asansol_Engineering_College.xlsx\n",
      "[INFO] Visiting depth 0: http://www.aecwb.edu.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Asansol_Engineering_College.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: http://www.aecwb.edu.in/mandatory-disclosure.php\n",
      "[INFO] Visiting depth 1: http://www.aecwb.edu.in/naac-cycles1.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: http://www.aecwb.edu.in/naac-ssr.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Asansol_Engineering_College.xlsx with 10 row(s).\n",
      "[INFO] Visiting depth 1: http://www.aecwb.edu.in/nba-accreditation.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Asansol_Engineering_College.xlsx with 12 row(s).\n",
      "[INFO] Visiting depth 1: http://www.aecwb.edu.in/nirf.html\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Asansol_Engineering_College.xlsx with 14 row(s).\n",
      "[INFO] Visiting depth 1: http://www.aecwb.edu.in/aicte-approval.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Asansol_Engineering_College.xlsx with 17 row(s).\n",
      "[INFO] Visiting depth 1: http://www.aecwb.edu.in/makaut-aicte-approval.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Asansol_Engineering_College.xlsx with 20 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: Netaji Subhash Engineering College | http://www.nsec.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx\n",
      "[INFO] Visiting depth 0: http://www.nsec.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 8 row(s).\n",
      "[INFO] Visiting depth 1: https://www.nsec.ac.in/page.php?id=318\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: https://www.nsec.ac.in/page.php?id=734\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 10 row(s).\n",
      "[INFO] Visiting depth 1: https://www.nsec.ac.in/page.php?id=533\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 14 row(s).\n",
      "[INFO] Visiting depth 1: https://www.nsec.ac.in/page.php?id=501\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 19 row(s).\n",
      "[INFO] Visiting depth 1: https://www.nsec.ac.in/page.php?id=574\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 26 row(s).\n",
      "[INFO] Visiting depth 1: https://www.nsec.ac.in/page.php?id=543\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 34 row(s).\n",
      "[INFO] Visiting depth 1: https://www.nsec.ac.in/page.php?id=632\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 42 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=512\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=738\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 45 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=748\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 49 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=740\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 54 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=742\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 60 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=749\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 73 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=739\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 86 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=736\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 99 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=741\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 112 row(s).\n",
      "[INFO] Visiting depth 2: https://www.nsec.ac.in/page.php?id=737\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Netaji_Subhash_Engineering_College.xlsx with 125 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: Govt. College Of Engg. & Textile Technology, Serampore | http://www.gcetts.org/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Govt_College_Of_Engg_Textile_Technology_Serampore.xlsx\n",
      "[INFO] Visiting depth 0: http://www.gcetts.org/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Govt_College_Of_Engg_Textile_Technology_Serampore.xlsx with 3 row(s).\n",
      "[INFO] Visiting depth 1: https://docs.google.com/document/d/1RNl_Yfe8uycfnQXqF3WdSlAdGlJ1kkH6g-bZ0tc5Gao/edit?usp=sharing\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Govt. College Of Engineering And Textile Technology, Berhampore | http://gcettb.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Govt_College_Of_Engineering_And_Textile_Technology_Berhampore.xlsx\n",
      "[INFO] Visiting depth 0: http://gcettb.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Govt_College_Of_Engineering_And_Textile_Technology_Berhampore.xlsx with 5 row(s).\n",
      "[INFO] Visiting depth 1: http://gcettb.ac.in/nep\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Government College Of Engineering And Leather Technology | http://www.gcelt.gov.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Government_College_Of_Engineering_And_Leather_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://www.gcelt.gov.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_And_Leather_Technology.xlsx with 2 row(s).\n",
      "[INFO] Visiting depth 1: https://gcelt.gov.in/iqac-cell/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Government College Of Engineering & Ceramic Technology | https://www.gcect.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx\n",
      "[INFO] Visiting depth 0: https://www.gcect.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: https://gcect.ac.in/mandatory-disclosures/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 10 row(s).\n",
      "[INFO] Visiting depth 1: https://gcect.ac.in/ugc-for-autonomous/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 14 row(s).\n",
      "[INFO] Visiting depth 1: https://gcect.ac.in/ssr-for-naac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 1: https://gcect.ac.in/iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 44 row(s).\n",
      "[INFO] Visiting depth 1: http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn\n",
      "[WARN] goto failed (attempt 1/3) :: http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn :: Page.goto: Download is starting\n",
      "Call log:\n",
      "  - navigating to \"http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[WARN] goto failed (attempt 2/3) :: http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn :: Page.goto: Download is starting\n",
      "Call log:\n",
      "  - navigating to \"http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[WARN] goto failed (attempt 3/3) :: http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn :: Page.goto: Download is starting\n",
      "Call log:\n",
      "  - navigating to \"http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[ERROR] Failed after retries: http://gcect.ac.in/download.php?action=start_download&file=TWlzY2VsbGFuZW91cy9za3ktd2F0Y2hpbmctY2FtcC5qcGVn\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 60 row(s).\n",
      "[INFO] Visiting depth 1: https://gcect.ac.in/question-paper-download/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 76 row(s).\n",
      "[INFO] Visiting depth 1: https://gcect.ac.in/assignment-download/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 92 row(s).\n",
      "[INFO] Visiting depth 2: https://docs.google.com/document/d/1vpB0zVpduHEEEUQLUPdABnFAnUiEIPTG3Y8agQUIZR0/edit?usp=sharing\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 2: https://gcect.ac.in/2-4-2-percentage-of-full-time-teachers-with-ph-d-d-sc-d-litt-l-l-d-during-the-last-five-years/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Government_College_Of_Engineering_Ceramic_Technology.xlsx with 93 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: B.P. Poddar Institute Of Management & Technology | http://www.bppimt.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://www.bppimt.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 5 row(s).\n",
      "[INFO] Visiting depth 1: https://bppimt.ac.in/other-information/mandatory-disclosure/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 7 row(s).\n",
      "[INFO] Visiting depth 1: https://bppimt.ac.in/other-information/nba/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 10 row(s).\n",
      "[INFO] Visiting depth 1: https://bppimt.ac.in/other-information/nirf/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 15 row(s).\n",
      "[INFO] Visiting depth 1: https://bppimt.ac.in/institute-cells/internal-quality-assurance-cell/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 20 row(s).\n",
      "[INFO] Visiting depth 1: https://bppimt.ac.in/news-events/aicte-atal-fdp-on-green-iot-with-ai-for-sustainable-growth-of-the-society/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 27 row(s).\n",
      "[INFO] Visiting depth 2: https://bppimt.ac.in/other-information/mandatory-disclosure/student\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 2: https://bppimt.ac.in/other-information/nba/student\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 2: https://bppimt.ac.in/other-information/nirf/student\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 2: https://bppimt.ac.in/news-events/aicte-atal-fdp-on-green-iot-with-ai-for-sustainable-growth-of-the-society/student\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 2: https://atalacademy.aicte.gov.in/signup\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/notifications\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 30 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/contact-us\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 31 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/verify-certificate\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 32 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/atal-documents\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 33 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 35 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/login\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 37 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/vaani-documents\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 39 row(s).\n",
      "[INFO] Visiting depth 3: https://atalacademy.aicte.gov.in/results\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_B_P_Poddar_Institute_Of_Management_Technology.xlsx with 41 row(s).\n",
      "[INFO] Visiting depth 4: https://atalacademy.aicte.gov.in/request-password-reset-otp\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 4: https://atalacademy.aicte.gov.in/request-password-reset\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Mckv Institute Of Engineering | http://www.mckvie.edu.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx\n",
      "[INFO] Visiting depth 0: http://www.mckvie.edu.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/mandatory-disclosure/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/naac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 11 row(s).\n",
      "[INFO] Visiting depth 1: https://mckvie.edu.in/affiliations-accreditations/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 14 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/nirf/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 18 row(s).\n",
      "[INFO] Visiting depth 1: https://www.mckvie.edu.in/iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 23 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/aicte-feedback/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/ariia/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 36 row(s).\n",
      "[INFO] Visiting depth 1: http://www.mckvie.edu.in/affiliations-accreditations-approvals/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 44 row(s).\n",
      "[INFO] Visiting depth 2: https://mckvie.edu.in/video-of-naac-peer-team-visit-held-on-13-10-2017-and-14-10-2017/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 2: http://www.mckvie.edu.in/ssr/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 45 row(s).\n",
      "[INFO] Visiting depth 2: http://www.mckvie.edu.in/aqar/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 47 row(s).\n",
      "[INFO] Visiting depth 2: http://www.mckvie.edu.in/contact-iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 49 row(s).\n",
      "[INFO] Visiting depth 2: https://www.mckvie.edu.in/aicte-approvals/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 52 row(s).\n",
      "[INFO] Visiting depth 2: https://www.mckvie.edu.in/nba-accreditations/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 55 row(s).\n",
      "[INFO] Visiting depth 3: https://www.mckvie.edu.in/aqar-supplimentary-docs/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Mckv_Institute_Of_Engineering.xlsx with 59 row(s).\n",
      "\n",
      "[COLLEGE] Starting processing: Rcc Institute Of Information Technology | http://rcciit.org/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Rcc_Institute_Of_Information_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://rcciit.org/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Rcc_Institute_Of_Information_Technology.xlsx with 6 row(s).\n",
      "[INFO] Visiting depth 1: https://rcciit.edu.in/naac\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Rcc_Institute_Of_Information_Technology.xlsx with 7 row(s).\n",
      "[INFO] Visiting depth 1: https://rcciit.edu.in/nirf/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Rcc_Institute_Of_Information_Technology.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: https://iqac.rcciit.org.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Rcc_Institute_Of_Information_Technology.xlsx with 12 row(s).\n",
      "[INFO] Visiting depth 1: https://rcciit.edu.in/download/rules-&-regulations\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Rcc_Institute_Of_Information_Technology.xlsx with 17 row(s).\n",
      "[INFO] Visiting depth 2: https://rcciit.edu.in/download/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Birbhum Institute Of Engineering & Technology | http://www.bietsuri.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Birbhum_Institute_Of_Engineering_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://www.bietsuri.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Birbhum_Institute_Of_Engineering_Technology.xlsx with 6 row(s).\n",
      "[INFO] Visiting depth 1: http://www.bietsuri.ac.in/downloads.php?paid=19\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Siliguri Institute Of Technology | http://www.sittechno.org/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Siliguri_Institute_Of_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://www.sittechno.org/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Dr. B. C. Roy Engineering College, Durgapur | http://bcrec.ac.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx\n",
      "[INFO] Visiting depth 0: http://bcrec.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 5 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/disclosure\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 7 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/downloads\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 10 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download-manager/MCA-Fees-2025.pdf/Fee%20Structure%20MCA\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 15 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download-manager/Fee-Structure-B.Tech-Lateral-2025-ok.pdf/Fee%20Structure%20B.Tech%20Lateral\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 20 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download-manager/B-Tech-Fee-Structure-Final-2025.pdf/Fee%20Structure%20B.Tech\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 25 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download/Calendar_July23_June24.pdf/Academic%20Calendar%20July%202023-June%202024\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 30 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download-manager/MBA_Fees_Structure_2025_Final_March_2025.pdf/Fee%20Structure%20MBA\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 35 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download-manager/M-Tech-Fees-2025.pdf/Fee%20Structure%20M.Tech\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 40 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download/Provisional_Examination_Calendar_2024_25.pdf/Provisional%20Examination%20Calendar%202024-25%20%281st%20Year%20only%29\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 45 row(s).\n",
      "[INFO] Visiting depth 1: http://bcrec.ac.in/display-download/Calendar_July24_June25.pdf/Academic%20Calendar%202024-25\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 50 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/disclosure-details/65a542b93645b\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 52 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/MCA-Fees-2025.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 54 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/MCA-Fees-2025.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 56 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/Fee-Structure-B.Tech-Lateral-2025-ok.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 58 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/Fee-Structure-B.Tech-Lateral-2025-ok.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 60 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/B-Tech-Fee-Structure-Final-2025.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 62 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/B-Tech-Fee-Structure-Final-2025.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 64 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download/Calendar_July23_June24.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 66 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download/Calendar_July23_June24.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 68 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/MBA_Fees_Structure_2025_Final_March_2025.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 70 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/MBA_Fees_Structure_2025_Final_March_2025.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 72 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/M-Tech-Fees-2025.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 74 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download-manager/M-Tech-Fees-2025.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 76 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download/Provisional_Examination_Calendar_2024_25.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 78 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download/Provisional_Examination_Calendar_2024_25.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 80 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download/Calendar_July24_June25.pdf/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 82 row(s).\n",
      "[INFO] Visiting depth 2: http://bcrec.ac.in/display-download/Calendar_July24_June25.pdf/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Dr_B_C_Roy_Engineering_College_Durgapur.xlsx with 84 row(s).\n",
      "[INFO] Visiting depth 3: http://bcrec.ac.in/disclosure-details/meeting-minutes.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Visiting depth 3: http://bcrec.ac.in/disclosure-details/audit-report.html\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "\n",
      "[COLLEGE] Starting processing: Bengal Institute Of Technology | http://bitcollege.in/\n",
      "[INIT] Created empty Excel: output_college_info_6_7/college_info_Bengal_Institute_Of_Technology.xlsx\n",
      "[INFO] Visiting depth 0: http://bitcollege.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bengal_Institute_Of_Technology.xlsx with 8 row(s).\n",
      "[INFO] Visiting depth 1: https://bitcollege.in/NAAC\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bengal_Institute_Of_Technology.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: https://bitcollege.in/NIRF\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bengal_Institute_Of_Technology.xlsx with 11 row(s).\n",
      "[INFO] Visiting depth 1: https://bitcollege.in/NIRF/nirfReport\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bengal_Institute_Of_Technology.xlsx with 13 row(s).\n",
      "[INFO] Visiting depth 1: https://bitcollege.in/IQAC/about\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[DEBUG] Scroll round 3/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_7/college_info_Bengal_Institute_Of_Technology.xlsx with 15 row(s).\n",
      "[INFO] Visiting depth 1: https://bitcollege.in/IQAC\n",
      "[DEBUG] Scroll round 1/3 completed\n"
     ]
    }
   ],
   "source": [
    "await run_scraping_from_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330ef79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca3a578a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[COLLEGE] Starting processing: Siddartha | https://siddhartha.org.in/\n",
      "[INFO] Visiting depth 0: https://siddhartha.org.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_Siddartha.xlsx with 2 row(s).\n",
      "[INFO] Visiting depth 1: https://siddhartha.org.in/iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_Siddartha.xlsx with 2 row(s).\n",
      "[INFO] Visiting depth 1: https://siddhartha.org.in/accreditations/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[DEBUG] Scroll round 3/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_Siddartha.xlsx with 3 row(s).\n",
      "[DONE] All colleges processed.\n"
     ]
    }
   ],
   "source": [
    "example = [\n",
    "     {\n",
    "        \"college_name\": \"Siddartha\",\n",
    "        \"base_url\": \"https://siddhartha.org.in/\",\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "df = await run_scraping(example)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d1e73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[COLLEGE] Starting processing: pallavi_engineering_college | https://pallaviengineeringcollege.ac.in/\n",
      "[INFO] Visiting depth 0: https://pallaviengineeringcollege.ac.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 8 row(s).\n",
      "[INFO] Visiting depth 1: https://pallaviengineeringcollege.ac.in/mandatory-disclosure.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 9 row(s).\n",
      "[INFO] Visiting depth 1: https://pallaviengineeringcollege.ac.in/nacc_ssr.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 16 row(s).\n",
      "[INFO] Visiting depth 1: https://pallaviengineeringcollege.ac.in/nirf_Information.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 17 row(s).\n",
      "[INFO] Visiting depth 1: https://pallaviengineeringcollege.ac.in/aictu_approvals.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 18 row(s).\n",
      "[INFO] Visiting depth 1: https://pallaviengineeringcollege.ac.in/nacc_aqar.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 19 row(s).\n",
      "[INFO] Visiting depth 1: https://pallaviengineeringcollege.ac.in/ariia.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 19 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/1-2-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 20 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/1.1.1-qim.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 21 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/1-2-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 21 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/2-7-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 21 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/2-4-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 23 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/2-1-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 23 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/2-1-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 23 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/2-2-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 23 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/3-4-3-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 24 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/3-3-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 25 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/3-1-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 25 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/3-3-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 25 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/3-2-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 25 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/4-2-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 27 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/4-3-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 27 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/4-1-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 27 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/4-4-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 27 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-1-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-1-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-2-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-2-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-3-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-3-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-1-3-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/5-1-4-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 28 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/6-2-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/6-3-2-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/6-3-1-qnm.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 2: https://pallaviengineeringcollege.ac.in/aqar23-24.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 29 row(s).\n",
      "[INFO] Visiting depth 3: https://pallaviengineeringcollege.ac.in/1-2-1-4-2020-2021.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 30 row(s).\n",
      "[INFO] Visiting depth 3: https://pallaviengineeringcollege.ac.in/1-2-1-5-2021-2022.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 30 row(s).\n",
      "[INFO] Visiting depth 3: https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2022/12/2.4.1%20PhD%20Faculty%20list%202020-2\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 30 row(s).\n",
      "[INFO] Visiting depth 3: https://www.pallaviengineeringcollege.ac.in/wp-content/uploads/2022/12/UGC%202017-18.pdfssss\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 30 row(s).\n",
      "[INFO] Visiting depth 3: https://pallaviengineeringcollege.ac.in/4-2-1-qnm(d).php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 31 row(s).\n",
      "[INFO] Visiting depth 3: https://pallaviengineeringcollege.ac.in/4-2-1-qnm(a).php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 31 row(s).\n",
      "[INFO] Visiting depth 3: https://pallaviengineeringcollege.ac.in/4-2-1-qnm(c).php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 31 row(s).\n",
      "[INFO] Visiting depth 3: https://pallaviengineeringcollege.ac.in/4-2-1-qnm(b).php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[PROGRESS] Updated output_college_info_6_3/college_info_pallavi_engineering_college.xlsx with 31 row(s).\n",
      "[DONE] All colleges processed.\n"
     ]
    }
   ],
   "source": [
    "example = [\n",
    "    {\"college_name\": \"pallavi_engineering_college\", \"base_url\": \"https://pallaviengineeringcollege.ac.in/\"},\n",
    "]\n",
    "\n",
    "df = await run_scraping(example)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18394a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Visiting depth 0: https://siddhartha.org.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info/college_info_Siddhartha_Institute_of_Technology_and_Sciences.xlsx with 2 row(s).\n",
      "[INFO] Visiting depth 1: https://siddhartha.org.in/iqac/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info/college_info_Siddhartha_Institute_of_Technology_and_Sciences.xlsx with 5 row(s).\n",
      "[INFO] Visiting depth 1: https://siddhartha.org.in/accreditations/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[DEBUG] Scroll round 2/3 completed\n",
      "[PROGRESS] Updated output_college_info/college_info_Siddhartha_Institute_of_Technology_and_Sciences.xlsx with 5 row(s).\n",
      "[DONE] All colleges processed.\n"
     ]
    }
   ],
   "source": [
    "example_colleges = [\n",
    "    {\n",
    "        \"college_name\": \"Siddhartha Institute of Technology and Sciences\",\n",
    "        \"base_url\": \"https://siddhartha.org.in/\",\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "await run_scraping(example_colleges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10358882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Visiting depth 0: https://www.vmtw.in/\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 3 row(s).\n",
      "[INFO] Visiting depth 1: https://www.vmtw.in/naac.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 6 row(s).\n",
      "[INFO] Visiting depth 1: https://www.vmtw.in/nirf.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 6 row(s).\n",
      "[INFO] Visiting depth 1: https://www.vmtw.in/about_iqac.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 6 row(s).\n",
      "[INFO] Visiting depth 1: https://www.vmtw.in/aicte_approvls.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 6 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/dvv_metric_level_deviation.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_4.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_06.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_1.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_07.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_03.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/dvv_ext_pro_deviation_1.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_02.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_6.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_04.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_7.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_01.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_2.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_3.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/dvv_ext_pro_deviation.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_05.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/dvv_metric_level_deviation_1.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/crit_5.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_qualitymandate.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_bestpractices.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_statutory.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_inst-distinctive.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_initiatives.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_Composition.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_activities.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 2: https://www.vmtw.in/IQAC_minutes.php\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 9 row(s).\n",
      "[INFO] Visiting depth 3: https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.2/4.2.3_Data_Template.xlsx\n",
      "[WARN] Page load issue https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.2/4.2.3_Data_Template.xlsx: Page.goto: Download is starting\n",
      "Call log:\n",
      "  - navigating to \"https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.2/4.2.3_Data_Template.xlsx\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 12 row(s).\n",
      "[INFO] Visiting depth 3: https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.1/4.1.3_Data_Template.xlsx\n",
      "[WARN] Page load issue https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.1/4.1.3_Data_Template.xlsx: Page.goto: Download is starting\n",
      "Call log:\n",
      "  - navigating to \"https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.1/4.1.3_Data_Template.xlsx\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 12 row(s).\n",
      "[INFO] Visiting depth 3: https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.2/4.2.2_Data Template.xlsx\n",
      "[WARN] Page load issue https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.2/4.2.2_Data Template.xlsx: Page.goto: Download is starting\n",
      "Call log:\n",
      "  - navigating to \"https://www.vmtw.in/pdf/NAAC/naac_cycle1/AQAR/quality_indicator/crit_04/4.2/4.2.2_Data%20Template.xlsx\", waiting until \"domcontentloaded\"\n",
      "\n",
      "[DEBUG] Scroll round 1/3 completed\n",
      "[INFO] Page fully converged ‚Äî stopping interactions\n",
      "[PROGRESS] Updated output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.xlsx and output_college_info_5/college_info_VIGNAN_S_INSTITUTE_OF_MANAGEMENT_AND_TECHNOLOGY_FOR_WOMEN.csv with 12 row(s).\n",
      "[DONE] All colleges processed.\n"
     ]
    }
   ],
   "source": [
    "example_colleges = [\n",
    "    {\n",
    "        \"college_name\": \"VIGNAN'S INSTITUTE OF MANAGEMENT AND TECHNOLOGY FOR WOMEN\",\n",
    "        \"base_url\": \"https://www.vmtw.in/\",\n",
    "    },\n",
    "]\n",
    "\n",
    "await run_scraping(example_colleges)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
